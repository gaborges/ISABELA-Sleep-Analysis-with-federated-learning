{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc3553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:59:24.893509: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 16:59:25.537439: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-25 16:59:27.045301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-02-25 16:59:27.047283: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-02-25 16:59:27.047298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "np.random.seed(0)\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    return results\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e68b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 3\n",
    "NUM_EPOCHS = EPOCHS\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "# outputs\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "# input folder\n",
    "inputFolders = baseFolder\n",
    "\n",
    "            \n",
    "dsTrain = ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "            'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4', \n",
    "            'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "            'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "            'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "            'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "            'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "            'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "\n",
    "\n",
    "# client datasets used on the training process\n",
    "dsTrain =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            #['PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc'], \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            #['rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw'], \n",
    "            #['RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI'], \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "            #['VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is'], \n",
    "            #['Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw'], \n",
    "            #['XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA'], \n",
    "            #['YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw'], \n",
    "            #['ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM'], \n",
    "            #['ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44b239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_numeric.csv\n",
      "1   ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_numeric.csv\n",
      "2   ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_numeric.csv\n",
      "3   ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_numeric.csv\n",
      "4   ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_numeric.csv\n",
      "5   ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_numeric.csv\n",
      "6   ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_numeric.csv\n",
      "7   ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_numeric.csv\n",
      "8   ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_numeric.csv\n",
      "9   ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_numeric.csv\n",
      "10   ../data_2019_processed/student_DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA_numeric.csv\n",
      "11   ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_numeric.csv\n",
      "12   ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_numeric.csv\n",
      "13   ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_numeric.csv\n",
      "14   ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_numeric.csv\n",
      "15   ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_numeric.csv\n",
      "16   ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_numeric.csv\n",
      "17   ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_numeric.csv\n",
      "18   ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_numeric.csv\n",
      "19   ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_numeric.csv\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "# load cliend data\n",
    "clientList = []\n",
    "\n",
    "# balancing classes\n",
    "oversample = RandomOverSampler(sampling_strategy='auto') #minority\n",
    "#undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "for i in range(0,len(dsTrain)):\n",
    "    print (i,\" \", str(inputFolders)+\"student_\"+dsTrain[i]+\"_numeric.csv\") #_numeric\n",
    "    # load client data\n",
    "    dataset = pd.read_csv(inputFolders+\"student_\"+dsTrain[i]+\"_numeric.csv\")\n",
    "    \n",
    "    # print(dataset)\n",
    "    y_train = dataset['class'].copy()\n",
    "    \n",
    "    # does not add datasets that dont have instances from both classes\n",
    "    if y_train.sum() != 0 and (y_train.sum() != len(y_train)):\n",
    "        X_train = dataset\n",
    "        # balancing classes\n",
    "        X_train, y_train = oversample.fit_resample(dataset, y_train)\n",
    "        #X_train, y_train = undersample.fit_resample(dataset, y_train)\n",
    "        \n",
    "        X_train['class'] = y_train\n",
    "        \n",
    "        clientList.append(X_train)\n",
    "        \n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7fdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 12.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>2018-05-15 02:46:57</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:27</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:57</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:28</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:57</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136281</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136282</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136283</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136284</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136285</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136286 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "1           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "2           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "3           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "4           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "136281      0.25       1.0   0.007015     0.166667  0.000056         1.0   \n",
       "136282      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136283      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136284      0.25       1.0   0.007016     0.166667  0.000085         1.0   \n",
       "136285      0.50       1.0   0.007016     0.166667  0.000000         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.655565            0.906151     0.115358   \n",
       "1             1.0  0.567296            0.906052     0.116053   \n",
       "2             1.0  0.567296            0.906052     0.116053   \n",
       "3             1.0  0.660604            0.905952     0.116748   \n",
       "4             1.0  0.660604            0.905952     0.116748   \n",
       "...           ...       ...                 ...          ...   \n",
       "136281        1.0  0.000000            0.000099     0.510076   \n",
       "136282        1.0  0.000000            0.000694     0.512856   \n",
       "136283        1.0  0.000000            0.000595     0.513551   \n",
       "136284        1.0  0.000000            0.000595     0.513551   \n",
       "136285        0.0  0.000000            0.000496     0.514246   \n",
       "\n",
       "             timestamp_text  class  \n",
       "0       2018-05-15 02:46:57  awake  \n",
       "1       2018-05-15 02:47:27  awake  \n",
       "2       2018-05-15 02:47:57  awake  \n",
       "3       2018-05-15 02:48:28  awake  \n",
       "4       2018-05-15 02:48:57  awake  \n",
       "...                     ...    ...  \n",
       "136281  2018-06-13 12:14:37  awake  \n",
       "136282  2018-06-13 12:18:08  awake  \n",
       "136283  2018-06-13 12:19:08  awake  \n",
       "136284  2018-06-13 12:19:38  awake  \n",
       "136285  2018-06-13 12:20:08  awake  \n",
       "\n",
       "[136286 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7473fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_numerical_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  uint8  \n",
      " 13  asleep              136286 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0830f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float32\n",
      " 1   location            136286 non-null  float32\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float32\n",
      " 4   light               136286 non-null  float32\n",
      " 5   phone_lock          136286 non-null  float32\n",
      " 6   proximity           136286 non-null  float32\n",
      " 7   sound               136286 non-null  float32\n",
      " 8   time_to_next_alarm  136286 non-null  float32\n",
      " 9   minutes_day         136286 non-null  float32\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  float32\n",
      " 13  asleep              136286 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56557625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:59:53.382825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 4, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:59:53.449733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:53.450002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:53.451451: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 16:59:53.458333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:53.458607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:53.458860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:56.488973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:56.489969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:56.489987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-25 16:59:56.490252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 16:59:56.491582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3144 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-02-25 16:59:56.509909: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n",
      "2023-02-25 17:00:01.740847: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 4, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transform to time series\n",
    "X_test_data, y_test_label = create_dataset_time_series_with_one_output(    #timestamp\n",
    "    X_test_data, \n",
    "    y_test_label, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data, y_test_label))\n",
    "#client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021a0803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 17:00:33.355478: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15689088 exceeds 10% of free system memory.\n",
      "2023-02-25 17:01:03.925945: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15152832 exceeds 10% of free system memory.\n",
      "2023-02-25 17:01:24.892825: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15705216 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform data to float32\n",
    "    #data = transform_data_type(data)\n",
    "\n",
    "    # transform to time series\n",
    "    data, labels = create_dataset_time_series_with_one_output(    #timestamp\n",
    "        data, \n",
    "        labels, \n",
    "        TIME_SERIES_SIZE, \n",
    "        TIME_STEP_SHIFT\n",
    "    )\n",
    "\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    #client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(128,input_shape=(4, 9,))) #return_sequences=True, \n",
    "    #model.add(LSTM(128,input_shape=(2, 9,)))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(LSTM(64,activation=\"tanh\"))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))#softmax,sigmoid\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9357a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               70656     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,914\n",
      "Trainable params: 70,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17708ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    #keras_model = create_keras_model()\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=client_train_dataset.element_spec,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), #BinaryCrossentropy\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58fa47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "fed_avg_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),#client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9279e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,512],\n",
      "      float32[128,512],\n",
      "      float32[512],\n",
      "      float32[128,2],\n",
      "      float32[2]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(fed_avg_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c2f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fed_avg_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da066c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 17:04:25.589016: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.88957316), ('loss', 0.26973212), ('num_examples', 924612), ('num_batches', 28898)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "result = fed_avg_process.next(state, federated_training_data[0:10])\n",
    "state = result.state\n",
    "metrics = result.metrics\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95aaa901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 17:16:26.977357: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 11s 2ms/step\n",
      "0.99861896 0.0013810721 0.5\n",
      "[[0.01829364 0.9817063 ]\n",
      " [0.01825794 0.9817421 ]\n",
      " [0.01821238 0.98178756]\n",
      " ...\n",
      " [0.01137346 0.98862654]\n",
      " [0.01138239 0.9886176 ]\n",
      " [0.01138698 0.988613  ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.194795\n",
      "Precision: 0.980040\n",
      "Recall: 0.004455\n",
      "F1 score: 0.008869\n",
      "Cohens kappa: 0.001562\n",
      "ROC AUC: 0.502036\n",
      "\\Confusion Matrix\n",
      "[[ 26056     10]\n",
      " [109725    491]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.193048\n",
      "Precision: 0.190144\n",
      "Recall: 0.999613\n",
      "F1 score: 0.319512\n",
      "Cohens kappa: 0.001543\n",
      "ROC AUC: 0.502029\n",
      "\\Confusion Matrix\n",
      "[[   491 109963]\n",
      " [    10  25818]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.19392142762800663\n",
      "precision:  0.5850921719504261\n",
      "recall:  0.5020338559374854\n",
      "f1_score:  0.16419068417298469\n",
      "cohen_kappa_score:  0.0015521404607268807\n",
      "roc_auc_score:  0.5020323399478427\n"
     ]
    }
   ],
   "source": [
    "#def keras_evaluate(state, round_num):\n",
    "    # Take our global model weights and push them back into a Keras model to\n",
    "    # use its standard `.evaluate()` method.\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "keras_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# get neural network weights\n",
    "weights = fed_avg_process.get_model_weights(state)\n",
    "weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "#tttt.model.assign_weights_to(keras_model)\n",
    "yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "maxX = yhat_probs.max()\n",
    "minX = yhat_probs.min()\n",
    "avgX = yhat_probs.mean()\n",
    "\n",
    "print(maxX,minX,avgX)\n",
    "print(yhat_probs)\n",
    "# predict crisp classes for test set deprecated\n",
    "#printMetrics(y_test,yhat_probs)\n",
    "test = list()\n",
    "\n",
    "xx = yhat_probs.round()\n",
    "\n",
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1bf6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "awake\n",
      "Accuracy: 0.808735\n",
      "Precision: 0.808735\n",
      "Recall: 1.000000\n",
      "F1 score: 0.894255\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[     0  26066]\n",
      " [     0 110216]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.810481\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[110454      0]\n",
      " [ 25828      0]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8096080186671755\n",
      "precision:  0.4043674146255558\n",
      "recall:  0.5\n",
      "f1_score:  0.4471273600597165\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d310c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8841083), ('loss', 0.29775512), ('num_examples', 216409), ('num_batches', 13530)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "result = fed_avg_process.next(state, federated_training_data[10:19])\n",
    "state = result.state\n",
    "metrics = result.metrics\n",
    "print('round  2, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19cf5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "0.99840134 0.0015986436 0.5\n",
      "[[0.9885041  0.01149592]\n",
      " [0.98887783 0.01112218]\n",
      " [0.98828065 0.01171938]\n",
      " ...\n",
      " [0.96846604 0.03153395]\n",
      " [0.968545   0.03145504]\n",
      " [0.9686016  0.03139841]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.808735\n",
      "Precision: 0.808735\n",
      "Recall: 1.000000\n",
      "F1 score: 0.894255\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[     0  26066]\n",
      " [     0 110216]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.810481\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[110454      0]\n",
      " [ 25828      0]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8096080186671755\n",
      "precision:  0.4043674146255558\n",
      "recall:  0.5\n",
      "f1_score:  0.4471273600597165\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#def keras_evaluate(state, round_num):\n",
    "    # Take our global model weights and push them back into a Keras model to\n",
    "    # use its standard `.evaluate()` method.\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "keras_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# get neural network weights\n",
    "weights = fed_avg_process.get_model_weights(state)\n",
    "weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "#tttt.model.assign_weights_to(keras_model)\n",
    "yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "maxX = yhat_probs.max()\n",
    "minX = yhat_probs.min()\n",
    "avgX = yhat_probs.mean()\n",
    "\n",
    "print(maxX,minX,avgX)\n",
    "print(yhat_probs)\n",
    "# predict crisp classes for test set deprecated\n",
    "#printMetrics(y_test,yhat_probs)\n",
    "test = list()\n",
    "\n",
    "xx = yhat_probs.round()\n",
    "\n",
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb906d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (0:2):\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*3+3,i*3+3+3,metrics))\n",
    "\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32b565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e0c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
