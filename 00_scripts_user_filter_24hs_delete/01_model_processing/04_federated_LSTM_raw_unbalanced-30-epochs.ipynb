{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc3553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "np.random.seed(0)\n",
    "from collections import Counter\n",
    "\n",
    "import datetime;\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    return results\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e68b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 30\n",
    "NUM_EPOCHS = EPOCHS\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "# outputs\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "# input folder\n",
    "inputFolders = baseFolder\n",
    "\n",
    "# client datasets used on the training process\n",
    "dsTrain =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            #['PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc'], \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            #['rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw'], \n",
    "            #['RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI'], \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "            #['VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is'], \n",
    "            #['Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw'], \n",
    "            #['XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA'], \n",
    "            #['YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw'], \n",
    "            #['ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM'], \n",
    "            #['ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']]\n",
    "            \n",
    "dsTrain = ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "            'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4', \n",
    "            'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "            'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "            'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "            'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "            'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "            'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44b239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_numeric.csv\n",
      "1   ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_numeric.csv\n",
      "2   ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_numeric.csv\n",
      "3   ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_numeric.csv\n",
      "4   ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_numeric.csv\n",
      "5   ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_numeric.csv\n",
      "6   ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_numeric.csv\n",
      "7   ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_numeric.csv\n",
      "8   ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_numeric.csv\n",
      "9   ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_numeric.csv\n",
      "10   ../data_2019_processed/student_DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA_numeric.csv\n",
      "11   ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_numeric.csv\n",
      "12   ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_numeric.csv\n",
      "13   ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_numeric.csv\n",
      "14   ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_numeric.csv\n",
      "15   ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_numeric.csv\n",
      "16   ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_numeric.csv\n",
      "17   ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_numeric.csv\n",
      "18   ../data_2019_processed/student_PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc_numeric.csv\n",
      "19   ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_numeric.csv\n",
      "20   ../data_2019_processed/student_rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw_numeric.csv\n",
      "21   ../data_2019_processed/student_RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI_numeric.csv\n",
      "22   ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_numeric.csv\n",
      "23   ../data_2019_processed/student_VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is_numeric.csv\n",
      "24   ../data_2019_processed/student_Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw_numeric.csv\n",
      "25   ../data_2019_processed/student_XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA_numeric.csv\n",
      "26   ../data_2019_processed/student_YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw_numeric.csv\n",
      "27   ../data_2019_processed/student_ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM_numeric.csv\n",
      "28   ../data_2019_processed/student_ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY_numeric.csv\n",
      "Total 28\n"
     ]
    }
   ],
   "source": [
    "# load cliend data\n",
    "clientList = []\n",
    "\n",
    "# balancing classes\n",
    "#oversample = RandomOverSampler(sampling_strategy='auto') #minority\n",
    "#undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "for i in range(0,len(dsTrain)):\n",
    "    print (i,\" \", str(inputFolders)+\"student_\"+dsTrain[i]+\"_numeric.csv\") #_numeric\n",
    "    # load client data\n",
    "    dataset = pd.read_csv(inputFolders+\"student_\"+dsTrain[i]+\"_numeric.csv\")\n",
    "    \n",
    "    # print(dataset)\n",
    "    y_train = dataset['class'].copy()\n",
    "    \n",
    "    # does not add datasets that dont have instances from both classes\n",
    "    if y_train.sum() != 0 and (y_train.sum() != len(y_train)):\n",
    "        X_train = dataset\n",
    "        # balancing classes\n",
    "        #X_train, y_train = oversample.fit_resample(dataset, y_train)\n",
    "        #X_train, y_train = undersample.fit_resample(dataset, y_train)\n",
    "        \n",
    "        X_train['class'] = y_train\n",
    "        \n",
    "        clientList.append(X_train)\n",
    "        \n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7fdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 12.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>2018-05-15 02:46:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:27</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:28</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136281</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136282</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136283</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136284</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136285</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136286 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "1           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "2           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "3           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "4           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "136281      0.25       1.0   0.007015     0.166667  0.000056         1.0   \n",
       "136282      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136283      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136284      0.25       1.0   0.007016     0.166667  0.000085         1.0   \n",
       "136285      0.50       1.0   0.007016     0.166667  0.000000         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.655565            0.906151     0.115358   \n",
       "1             1.0  0.567296            0.906052     0.116053   \n",
       "2             1.0  0.567296            0.906052     0.116053   \n",
       "3             1.0  0.660604            0.905952     0.116748   \n",
       "4             1.0  0.660604            0.905952     0.116748   \n",
       "...           ...       ...                 ...          ...   \n",
       "136281        1.0  0.000000            0.000099     0.510076   \n",
       "136282        1.0  0.000000            0.000694     0.512856   \n",
       "136283        1.0  0.000000            0.000595     0.513551   \n",
       "136284        1.0  0.000000            0.000595     0.513551   \n",
       "136285        0.0  0.000000            0.000496     0.514246   \n",
       "\n",
       "             timestamp_text   class  \n",
       "0       2018-05-15 02:46:57  asleep  \n",
       "1       2018-05-15 02:47:27  asleep  \n",
       "2       2018-05-15 02:47:57  asleep  \n",
       "3       2018-05-15 02:48:28  asleep  \n",
       "4       2018-05-15 02:48:57  asleep  \n",
       "...                     ...     ...  \n",
       "136281  2018-06-13 12:14:37   awake  \n",
       "136282  2018-06-13 12:18:08   awake  \n",
       "136283  2018-06-13 12:19:08   awake  \n",
       "136284  2018-06-13 12:19:38   awake  \n",
       "136285  2018-06-13 12:20:08   awake  \n",
       "\n",
       "[136286 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7473fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_numerical_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  uint8  \n",
      " 13  asleep              136286 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0830f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float32\n",
      " 1   location            136286 non-null  float32\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float32\n",
      " 4   light               136286 non-null  float32\n",
      " 5   phone_lock          136286 non-null  float32\n",
      " 6   proximity           136286 non-null  float32\n",
      " 7   sound               136286 non-null  float32\n",
      " 8   time_to_next_alarm  136286 non-null  float32\n",
      " 9   minutes_day         136286 non-null  float32\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  float32\n",
      " 13  asleep              136286 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56557625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 13:07:50.117606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:50.195765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:50.196311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:50.198322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 13:07:50.202364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built witho"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 4, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ut NUMA support.\n",
      "2023-03-04 13:07:50.202816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:50.203114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:53.262694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:53.264719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:53.264755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-04 13:07:53.265240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-04 13:07:53.267249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 574 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-03-04 13:07:53.292018: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n",
      "2023-03-04 13:07:54.301484: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 4, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transform to time series\n",
    "X_test_data, y_test_label = create_dataset_time_series_with_one_output(    #timestamp\n",
    "    X_test_data, \n",
    "    y_test_label, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data, y_test_label))\n",
    "#client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021a0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform data to float32\n",
    "    #data = transform_data_type(data)\n",
    "\n",
    "    # transform to time series\n",
    "    data, labels = create_dataset_time_series_with_one_output(    #timestamp\n",
    "        data, \n",
    "        labels, \n",
    "        TIME_SERIES_SIZE, \n",
    "        TIME_STEP_SHIFT\n",
    "    )\n",
    "\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    #client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(128,input_shape=(4, 9,))) #return_sequences=True, \n",
    "    #model.add(LSTM(128,input_shape=(2, 9,)))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(LSTM(64,activation=\"tanh\"))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))#softmax,sigmoid\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9357a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               70656     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,914\n",
      "Trainable params: 70,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17708ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    #keras_model = create_keras_model()\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=client_train_dataset.element_spec,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), #BinaryCrossentropy\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58fa47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "fed_avg_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),#client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9279e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,512],\n",
      "      float32[128,512],\n",
      "      float32[512],\n",
      "      float32[128,2],\n",
      "      float32[2]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(fed_avg_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c2f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fed_avg_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da066c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start timestamp: 1677939801.527352 2023-03-04 14:23:21.527352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:23:32.072025: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.83657944), ('precision', 0.83527976), ('loss', 0.378862), ('num_examples', 5728980), ('num_batches', 179034)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "End timestamp: 1677944374.697553 2023-03-04 15:39:34.697553\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "result = fed_avg_process.next(state, federated_training_data[0:10])\n",
    "state = result.state\n",
    "metrics = result.metrics\n",
    "print('round  1, metrics={}'.format(metrics))\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"End timestamp:\", time_stamp,current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95aaa901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 15:39:35.133146: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n",
      "2023-03-04 15:39:35.277175: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n",
      "2023-03-04 15:39:38.155643: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 13s 2ms/step\n",
      "0.9838154 0.016184678 0.5\n",
      "[[0.8782575  0.12174246]\n",
      " [0.8813447  0.11865527]\n",
      " [0.87621903 0.12378095]\n",
      " ...\n",
      " [0.8585065  0.14149348]\n",
      " [0.85854703 0.14145297]\n",
      " [0.85858154 0.1414184 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.709881\n",
      "Precision: 0.707953\n",
      "Recall: 0.998096\n",
      "F1 score: 0.828352\n",
      "Cohens kappa: 0.042904\n",
      "ROC AUC: 0.515523\n",
      "\\Confusion Matrix\n",
      "[[ 1341 39356]\n",
      " [  182 95403]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.711547\n",
      "Precision: 0.879186\n",
      "Recall: 0.033090\n",
      "F1 score: 0.063779\n",
      "Cohens kappa: 0.043168\n",
      "ROC AUC: 0.515585\n",
      "\\Confusion Matrix\n",
      "[[95632   184]\n",
      " [39127  1339]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7107138140033167\n",
      "precision:  0.7935692665270488\n",
      "recall:  0.5155927213976942\n",
      "f1_score:  0.44606549299857856\n",
      "cohen_kappa_score:  0.043036361729402284\n",
      "roc_auc_score:  0.5155539818049104\n"
     ]
    }
   ],
   "source": [
    "#def keras_evaluate(state, round_num):\n",
    "    # Take our global model weights and push them back into a Keras model to\n",
    "    # use its standard `.evaluate()` method.\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "keras_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# get neural network weights\n",
    "weights = fed_avg_process.get_model_weights(state)\n",
    "weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "#tttt.model.assign_weights_to(keras_model)\n",
    "yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "maxX = yhat_probs.max()\n",
    "minX = yhat_probs.min()\n",
    "avgX = yhat_probs.mean()\n",
    "\n",
    "print(maxX,minX,avgX)\n",
    "print(yhat_probs)\n",
    "# predict crisp classes for test set deprecated\n",
    "#printMetrics(y_test,yhat_probs)\n",
    "test = list()\n",
    "\n",
    "xx = yhat_probs.round()\n",
    "\n",
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1bf6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "awake\n",
      "Accuracy: 0.709881\n",
      "Precision: 0.707953\n",
      "Recall: 0.998096\n",
      "F1 score: 0.828352\n",
      "Cohens kappa: 0.042904\n",
      "ROC AUC: 0.515523\n",
      "\\Confusion Matrix\n",
      "[[ 1341 39356]\n",
      " [  182 95403]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.711547\n",
      "Precision: 0.879186\n",
      "Recall: 0.033090\n",
      "F1 score: 0.063779\n",
      "Cohens kappa: 0.043168\n",
      "ROC AUC: 0.515585\n",
      "\\Confusion Matrix\n",
      "[[95632   184]\n",
      " [39127  1339]]\n",
      "\n",
      "Global\n",
      "4\n",
      "accuracy:  0.7107138140033167\n",
      "precision:  0.7935692665270488\n",
      "recall:  0.5155927213976941\n",
      "f1_score:  0.44606549299857856\n",
      "cohen_kappa_score:  0.043036361729402284\n",
      "roc_auc_score:  0.5155539818049104\n"
     ]
    }
   ],
   "source": [
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d310c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start timestamp: 1677944392.439174 2023-03-04 15:39:52.439174\n",
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8570261), ('precision', 0.8558325), ('loss', 0.3386606), ('num_examples', 6152940), ('num_batches', 192283)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "End timestamp: 1677949240.372085 2023-03-04 17:00:40.372085\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"Start timestamp:\", time_stamp,current_time)\n",
    "\n",
    "result = fed_avg_process.next(state, federated_training_data[10:19])\n",
    "state = result.state\n",
    "metrics = result.metrics\n",
    "print('round  2, metrics={}'.format(metrics))\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"End timestamp:\", time_stamp,current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19cf5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 17:00:40.604182: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19624608 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "0.9864123 0.013587741 0.5\n",
      "[[0.8403469  0.15965317]\n",
      " [0.8522035  0.14779651]\n",
      " [0.84086245 0.15913753]\n",
      " ...\n",
      " [0.87140274 0.12859732]\n",
      " [0.8715912  0.12840877]\n",
      " [0.87172055 0.1282794 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.718796\n",
      "Precision: 0.730966\n",
      "Recall: 0.947973\n",
      "F1 score: 0.825445\n",
      "Cohens kappa: 0.160668\n",
      "ROC AUC: 0.564251\n",
      "\\Confusion Matrix\n",
      "[[ 7347 33350]\n",
      " [ 4973 90612]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.720124\n",
      "Precision: 0.594318\n",
      "Recall: 0.180942\n",
      "F1 score: 0.277422\n",
      "Cohens kappa: 0.161155\n",
      "ROC AUC: 0.564390\n",
      "\\Confusion Matrix\n",
      "[[90818  4998]\n",
      " [33144  7322]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7194603836163249\n",
      "precision:  0.6626420614968517\n",
      "recall:  0.5644575168606237\n",
      "f1_score:  0.5514335824069798\n",
      "cohen_kappa_score:  0.16091158798916355\n",
      "roc_auc_score:  0.5643204582451413\n"
     ]
    }
   ],
   "source": [
    "#def keras_evaluate(state, round_num):\n",
    "    # Take our global model weights and push them back into a Keras model to\n",
    "    # use its standard `.evaluate()` method.\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "keras_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# get neural network weights\n",
    "weights = fed_avg_process.get_model_weights(state)\n",
    "weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "#tttt.model.assign_weights_to(keras_model)\n",
    "yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "maxX = yhat_probs.max()\n",
    "minX = yhat_probs.min()\n",
    "avgX = yhat_probs.mean()\n",
    "\n",
    "print(maxX,minX,avgX)\n",
    "print(yhat_probs)\n",
    "# predict crisp classes for test set deprecated\n",
    "#printMetrics(y_test,yhat_probs)\n",
    "test = list()\n",
    "\n",
    "xx = yhat_probs.round()\n",
    "\n",
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "428e6f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Start timestamp: 1677949252.178667 2023-03-04 17:00:52.178667\n",
      "round  2-4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.85537136), ('precision', 0.85414106), ('loss', 0.34289375), ('num_examples', 11881920), ('num_batches', 371317)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "0.985007 0.014993022 0.5\n",
      "[[0.84831166 0.15168834]\n",
      " [0.86372554 0.13627444]\n",
      " [0.8525518  0.1474482 ]\n",
      " ...\n",
      " [0.8612799  0.1387201 ]\n",
      " [0.8614126  0.13858742]\n",
      " [0.8615367  0.13846333]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.731498\n",
      "Precision: 0.741215\n",
      "Recall: 0.948245\n",
      "F1 score: 0.832045\n",
      "Cohens kappa: 0.210275\n",
      "ROC AUC: 0.585335\n",
      "\\Confusion Matrix\n",
      "[[ 9052 31645]\n",
      " [ 4947 90638]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.732841\n",
      "Precision: 0.644903\n",
      "Recall: 0.223101\n",
      "F1 score: 0.331516\n",
      "Cohens kappa: 0.211100\n",
      "ROC AUC: 0.585610\n",
      "\\Confusion Matrix\n",
      "[[90845  4971]\n",
      " [31438  9028]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7321693253694546\n",
      "precision:  0.6930591288530081\n",
      "recall:  0.5856729461660757\n",
      "f1_score:  0.5817803718885243\n",
      "cohen_kappa_score:  0.2106876581949746\n",
      "roc_auc_score:  0.5854723654157776\n",
      "\n",
      "2 End timestamp: 1677958658.608856 2023-03-04 19:37:38.608856\n",
      "\n",
      "\n",
      "4 Start timestamp: 1677958658.608915 2023-03-04 19:37:38.608915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m time_stamp \u001b[38;5;241m=\u001b[39m current_time\u001b[38;5;241m.\u001b[39mtimestamp()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart timestamp:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_stamp,current_time)\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfed_avg_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_training_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m state \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m      9\u001b[0m metrics \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:135\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    134\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:67\u001b[0m, in \u001b[0;36mExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:223\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"Start timestamp:\", time_stamp,current_time)\n",
    "\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "    \n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"End timestamp:\", time_stamp,current_time)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb906d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,4):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"Start timestamp:\", time_stamp,current_time)\n",
    "\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"End timestamp:\", time_stamp,current_time)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime;\n",
    "  \n",
    "current_time = datetime.datetime.now()\n",
    "  \n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"Start timestamp:-\", time_stamp,current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4,6):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"End timestamp:\", time_stamp,current_time)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8b253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Start timestamp: 1677876295.287352 2023-03-03 20:44:55.287352\n",
      "round  14-16, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.84840226), ('precision', 0.8471487), ('loss', 0.3568586), ('num_examples', 3960640), ('num_batches', 123779)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "4259/4259 [==============================] - 9s 2ms/step\n",
      "0.9879844 0.012015647 0.5\n",
      "[[0.8380231  0.16197689]\n",
      " [0.8495376  0.15046233]\n",
      " [0.83833677 0.16166326]\n",
      " ...\n",
      " [0.8180887  0.18191127]\n",
      " [0.81829    0.18171003]\n",
      " [0.81843585 0.18156414]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.730918\n",
      "Precision: 0.741772\n",
      "Recall: 0.945504\n",
      "F1 score: 0.831338\n",
      "Cohens kappa: 0.211620\n",
      "ROC AUC: 0.586212\n",
      "\\Confusion Matrix\n",
      "[[ 9235 31462]\n",
      " [ 5209 90376]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.732202\n",
      "Precision: 0.637427\n",
      "Recall: 0.227524\n",
      "F1 score: 0.335349\n",
      "Cohens kappa: 0.212300\n",
      "ROC AUC: 0.586434\n",
      "\\Confusion Matrix\n",
      "[[90579  5237]\n",
      " [31259  9207]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7315602940960655\n",
      "precision:  0.6895995832256505\n",
      "recall:  0.5865141715481658\n",
      "f1_score:  0.5833433717125107\n",
      "cohen_kappa_score:  0.2119597135866979\n",
      "roc_auc_score:  0.5863231010189938\n",
      "\n",
      "14 End timestamp: 1677879431.772767 2023-03-03 21:37:11.772767\n",
      "\n",
      "\n",
      "16 Start timestamp: 1677879431.772798 2023-03-03 21:37:11.772798\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m time_stamp \u001b[38;5;241m=\u001b[39m current_time\u001b[38;5;241m.\u001b[39mtimestamp()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart timestamp:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_stamp,current_time)\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfed_avg_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_training_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m state \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:135\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    134\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:67\u001b[0m, in \u001b[0;36mExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:223\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(6,7):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"End timestamp:\", time_stamp,current_time)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9698a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Start timestamp: 1677961381.306848 2023-03-04 20:23:01.306848\n",
      "round  16-18, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8641499), ('precision', 0.86294705), ('loss', 0.32803243), ('num_examples', 11881920), ('num_batches', 371317)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "0.9891698 0.010830211 0.5\n",
      "[[0.87159854 0.12840146]\n",
      " [0.8845958  0.11540413]\n",
      " [0.8761793  0.12382074]\n",
      " ...\n",
      " [0.8562591  0.14374092]\n",
      " [0.8564318  0.1435682 ]\n",
      " [0.85659146 0.14340849]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.729693\n",
      "Precision: 0.729755\n",
      "Recall: 0.976063\n",
      "F1 score: 0.835127\n",
      "Cohens kappa: 0.164562\n",
      "ROC AUC: 0.563553\n",
      "\\Confusion Matrix\n",
      "[[ 6147 34550]\n",
      " [ 2288 93297]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.731124\n",
      "Precision: 0.726615\n",
      "Recall: 0.151460\n",
      "F1 score: 0.250670\n",
      "Cohens kappa: 0.165152\n",
      "ROC AUC: 0.563697\n",
      "\\Confusion Matrix\n",
      "[[93510  2306]\n",
      " [34337  6129]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7304082710849562\n",
      "precision:  0.7281851956553599\n",
      "recall:  0.5637618375883814\n",
      "f1_score:  0.5428981457016874\n",
      "cohen_kappa_score:  0.16485683047811506\n",
      "roc_auc_score:  0.5636249469820767\n",
      "\n",
      "16 End timestamp: 1677977406.065921 2023-03-05 00:50:06.065921\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(7,8):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"End timestamp:\", time_stamp,current_time)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64da9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Start timestamp: 1677977406.098739 2023-03-05 00:50:06.098739\n",
      "round  18-20, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8735254), ('precision', 0.87233984), ('loss', 0.310535), ('num_examples', 11881920), ('num_batches', 371317)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "0.99354 0.00646004 0.5\n",
      "[[0.8905278  0.10947224]\n",
      " [0.9025497  0.09745031]\n",
      " [0.8948299  0.10517015]\n",
      " ...\n",
      " [0.8444267  0.1555733 ]\n",
      " [0.8446905  0.15530951]\n",
      " [0.84497166 0.15502836]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.725334\n",
      "Precision: 0.725111\n",
      "Recall: 0.979850\n",
      "F1 score: 0.833451\n",
      "Cohens kappa: 0.140746\n",
      "ROC AUC: 0.553701\n",
      "\\Confusion Matrix\n",
      "[[ 5191 35506]\n",
      " [ 1926 93659]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.726721\n",
      "Precision: 0.726430\n",
      "Recall: 0.127762\n",
      "F1 score: 0.217304\n",
      "Cohens kappa: 0.141006\n",
      "ROC AUC: 0.553721\n",
      "\\Confusion Matrix\n",
      "[[93869  1947]\n",
      " [35296  5170]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7260276485522665\n",
      "precision:  0.7257704835918211\n",
      "recall:  0.5538059862785814\n",
      "f1_score:  0.5253775000311498\n",
      "cohen_kappa_score:  0.1408761334650354\n",
      "roc_auc_score:  0.5537110437381474\n",
      "\n",
      "18 End timestamp: 1677986790.314211 2023-03-05 03:26:30.314211\n",
      "\n",
      "\n",
      "20 Start timestamp: 1677986790.314243 2023-03-05 03:26:30.314243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m time_stamp \u001b[38;5;241m=\u001b[39m current_time\u001b[38;5;241m.\u001b[39mtimestamp()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart timestamp:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_stamp,current_time)\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfed_avg_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_training_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m state \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:135\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    134\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:67\u001b[0m, in \u001b[0;36mExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:223\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8,16):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i*2+2,\"End timestamp:\", time_stamp,current_time)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85f4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
