{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2701ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 22:30:28.112368: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 22:30:28.496687: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-13 22:30:29.558757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-13 22:30:29.561437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-13 22:30:29.561454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# example of random oversampling to balance the class distribution\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e61842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    return results\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        if(dataframe[column].dtypes in ()):\n",
    "            dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    #for column in outputClasses:\n",
    "    #    if(dataframe[column].dtypes != object):\n",
    "    #        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f392d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized.csv\")\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "#X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized_balanced_undersample.csv\")\n",
    "#X_train  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized_balanced_oversample.csv\")\n",
    "X_train  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized_balanced_oversample_smote.csv\")\n",
    "\n",
    "#AA = pd.read_csv(baseFolder+\"allData-classification-numeric-normalized.csv\")\n",
    "#X_train, X_test = train_test_split(AA,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413d6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 191398 entries, 0 to 191397\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            191398 non-null  float64\n",
      " 1   location            191398 non-null  float64\n",
      " 2   day_of_week         191398 non-null  float64\n",
      " 3   light               191398 non-null  float64\n",
      " 4   phone_lock          191398 non-null  float64\n",
      " 5   proximity           191398 non-null  float64\n",
      " 6   sound               191398 non-null  float64\n",
      " 7   time_to_next_alarm  191398 non-null  float64\n",
      " 8   minutes_day         191398 non-null  float64\n",
      " 9   class               191398 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 14.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191393</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777203</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.461189</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191394</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017182</td>\n",
       "      <td>0.359143</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191395</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.564570</td>\n",
       "      <td>0.960827</td>\n",
       "      <td>0.691889</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191396</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804258</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.474613</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191397</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>0.228857</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191398 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  day_of_week  light  phone_lock  proximity  \\\n",
       "0           0.00       1.0     1.000000    0.0         0.0        1.0   \n",
       "1           0.25       1.0     1.000000    0.0         0.0        1.0   \n",
       "2           0.25       1.0     1.000000    0.0         0.0        1.0   \n",
       "3           0.25       1.0     1.000000    0.0         0.0        1.0   \n",
       "4           0.25       1.0     1.000000    0.0         0.0        1.0   \n",
       "...          ...       ...          ...    ...         ...        ...   \n",
       "191393      0.25       1.0     1.000000    0.0         1.0        1.0   \n",
       "191394      0.25       1.0     1.000000    0.0         1.0        1.0   \n",
       "191395      0.25       0.5     0.000000    0.0         0.0        1.0   \n",
       "191396      0.25       1.0     0.833333    0.0         1.0        0.0   \n",
       "191397      0.25       1.0     0.000000    0.0         1.0        1.0   \n",
       "\n",
       "           sound  time_to_next_alarm  minutes_day   class  \n",
       "0       0.655565            0.906151     0.115358  asleep  \n",
       "1       0.567296            0.906052     0.116053  asleep  \n",
       "2       0.567296            0.906052     0.116053  asleep  \n",
       "3       0.660604            0.905952     0.116748  asleep  \n",
       "4       0.660604            0.905952     0.116748  asleep  \n",
       "...          ...                 ...          ...     ...  \n",
       "191393  0.777203            0.005987     0.461189  asleep  \n",
       "191394  0.000000            0.017182     0.359143  asleep  \n",
       "191395  0.564570            0.960827     0.691889  asleep  \n",
       "191396  0.804258            0.001468     0.474613  asleep  \n",
       "191397  0.000000            0.026853     0.228857  asleep  \n",
       "\n",
       "[191398 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.info())\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5feb752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'asleep': 95699, 'awake': 95699})\n"
     ]
    }
   ],
   "source": [
    "# transforms the input data to float32\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "# transforms the input data to float32\n",
    "X_train = transform_data_type(X_train)\n",
    "\n",
    "\n",
    "# balance\n",
    "#print(Counter(X_train['class']))\n",
    "#smote = SMOTE(random_state = 32)\n",
    "#X_train, y_train = smote.fit_resample(X_train[inputFeatures], X_train['class'])\n",
    "#X_train['class'] = y_train\n",
    "print(Counter(X_train['class']))\n",
    "\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_train = transform_output_nominal_class_into_one_hot_encoding(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a601ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf8855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (191394, 4, 9) (191394, 2)\n",
      "Size:  (136282, 4, 9) (136282, 2)\n"
     ]
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_train_data = pd.DataFrame(data=X_train,columns=inputFeatures)\n",
    "y_train_data = pd.DataFrame(data=X_train,columns=outputClasses)\n",
    "# selec test dataset (fixed to all)\n",
    "X_test_data = pd.DataFrame(data=X_test,columns=inputFeatures)\n",
    "y_test_data = pd.DataFrame(data=X_test,columns=outputClasses)\n",
    "\n",
    "X_train_data, y_train_data = create_dataset_time_series_with_one_output(   #timestamp\n",
    "    X_train_data, \n",
    "    y_train_data, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "X_test_data, y_test_data = create_dataset_time_series_with_one_output(    #timestamp\n",
    "    X_test_data, \n",
    "    y_test_data, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "\n",
    "print(\"shape: \",X_train_data.shape, y_train_data.shape)\n",
    "print(\"Size: \",X_test_data.shape,y_test_data.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7518d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 22:31:41.297162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:41.355851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:41.356221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:41.357736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 22:31:41.360901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:41.361229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:41.361511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:43.033077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:43.037216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:43.037240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-13 22:31:43.037611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 22:31:43.038796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2957 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-03-13 22:31:43.044107: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39249216 exceeds 10% of free system memory.\n",
      "2023-03-13 22:31:47.649714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39249216 exceeds 10% of free system memory.\n",
      "2023-03-13 22:31:47.679375: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 55121472 exceeds 10% of free system memory.\n",
      "2023-03-13 22:31:48.125254: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 55121472 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# transtorm data to tensor slices\n",
    "test_dataset_series = tf.data.Dataset.from_tensor_slices((X_test_data, y_test_data))\n",
    "train_dataset_series = tf.data.Dataset.from_tensor_slices((X_train_data, y_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de06a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(4, 9), dtype=tf.float64, name=None), TensorSpec(shape=(2,), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc486e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client_test_dataset.window(size=4, shift=1, stride=1, drop_remainder=True)\n",
    "#test_dataset_series.batch(BATCH_SIZE) # usado no federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97211c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 4, 9), dtype=tf.float64, name=None), TensorSpec(shape=(None, 2), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch data size\n",
    "#test_dataset_series1 = test_dataset_series.batch(1)\n",
    "#train_dataset_series1 = train_dataset_series.batch(1)\n",
    "\n",
    "test_dataset_series1 = test_dataset_series.batch(BATCH_SIZE)\n",
    "train_dataset_series1 = train_dataset_series.batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset_series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06366f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c846c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 22:31:49.269367: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27560736 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 22:32:20.577193: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-03-13 22:32:31.769541: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5982/5982 [==============================] - 91s 8ms/step - loss: 0.4227 - categorical_accuracy: 0.8031\n",
      "Epoch 2/2\n",
      "5982/5982 [==============================] - 48s 8ms/step - loss: 0.3589 - categorical_accuracy: 0.8350\n",
      "4259/4259 [==============================] - 11s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.782583\n",
      "Precision: 0.814686\n",
      "Recall: 0.893184\n",
      "F1 score: 0.852131\n",
      "Cohens kappa: 0.444907\n",
      "ROC AUC: 0.828295\n",
      "\\Confusion Matrix\n",
      "[[21277 19420]\n",
      " [10210 85375]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.782913\n",
      "Precision: 0.672786\n",
      "Recall: 0.523501\n",
      "F1 score: 0.588829\n",
      "Cohens kappa: 0.444457\n",
      "ROC AUC: 0.828043\n",
      "\\Confusion Matrix\n",
      "[[85513 10303]\n",
      " [19282 21184]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7827482719654834\n",
      "precision:  0.7437357046088131\n",
      "recall:  0.7083426439463123\n",
      "f1_score:  0.720479885002507\n",
      "cohen_kappa_score:  0.4446823647952441\n",
      "roc_auc_score:  0.828168743046872\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a844945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/7\n",
      "5982/5982 [==============================] - 48s 8ms/step - loss: 0.4255 - categorical_accuracy: 0.8026\n",
      "Epoch 2/7\n",
      "5982/5982 [==============================] - 51s 9ms/step - loss: 0.3613 - categorical_accuracy: 0.8339\n",
      "Epoch 3/7\n",
      "5982/5982 [==============================] - 53s 9ms/step - loss: 0.3321 - categorical_accuracy: 0.8444\n",
      "Epoch 4/7\n",
      "5982/5982 [==============================] - 50s 8ms/step - loss: 0.3093 - categorical_accuracy: 0.8542\n",
      "Epoch 5/7\n",
      "5982/5982 [==============================] - 50s 8ms/step - loss: 0.2895 - categorical_accuracy: 0.8630\n",
      "Epoch 6/7\n",
      "5982/5982 [==============================] - 47s 8ms/step - loss: 0.2741 - categorical_accuracy: 0.8713\n",
      "Epoch 7/7\n",
      "5982/5982 [==============================] - 48s 8ms/step - loss: 0.2587 - categorical_accuracy: 0.8788\n",
      "4259/4259 [==============================] - 12s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.842716\n",
      "Precision: 0.895332\n",
      "Recall: 0.878443\n",
      "F1 score: 0.886807\n",
      "Cohens kappa: 0.629242\n",
      "ROC AUC: 0.914483\n",
      "\\Confusion Matrix\n",
      "[[30881  9816]\n",
      " [11619 83966]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.842709\n",
      "Precision: 0.723882\n",
      "Recall: 0.760268\n",
      "F1 score: 0.741629\n",
      "Cohens kappa: 0.628667\n",
      "ROC AUC: 0.914356\n",
      "\\Confusion Matrix\n",
      "[[84081 11735]\n",
      " [ 9701 30765]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8427121703526511\n",
      "precision:  0.809607039855886\n",
      "recall:  0.8193555747974244\n",
      "f1_score:  0.8142181002596872\n",
      "cohen_kappa_score:  0.6289542998148093\n",
      "roc_auc_score:  0.9144196261115825\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 7, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2d704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/15\n",
      "5982/5982 [==============================] - 52s 8ms/step - loss: 0.4258 - categorical_accuracy: 0.8003\n",
      "Epoch 2/15\n",
      "5982/5982 [==============================] - 51s 8ms/step - loss: 0.3616 - categorical_accuracy: 0.8331\n",
      "Epoch 3/15\n",
      "5982/5982 [==============================] - 48s 8ms/step - loss: 0.3327 - categorical_accuracy: 0.8446\n",
      "Epoch 4/15\n",
      "5982/5982 [==============================] - 50s 8ms/step - loss: 0.3094 - categorical_accuracy: 0.8550\n",
      "Epoch 5/15\n",
      "5982/5982 [==============================] - 52s 9ms/step - loss: 0.2928 - categorical_accuracy: 0.8630\n",
      "Epoch 6/15\n",
      "5982/5982 [==============================] - 51s 9ms/step - loss: 0.2781 - categorical_accuracy: 0.8692\n",
      "Epoch 7/15\n",
      "5982/5982 [==============================] - 50s 8ms/step - loss: 0.2653 - categorical_accuracy: 0.8755\n",
      "Epoch 8/15\n",
      "5982/5982 [==============================] - 50s 8ms/step - loss: 0.2526 - categorical_accuracy: 0.8812\n",
      "Epoch 9/15\n",
      "5982/5982 [==============================] - 51s 9ms/step - loss: 0.2417 - categorical_accuracy: 0.8869\n",
      "Epoch 10/15\n",
      "5982/5982 [==============================] - 51s 8ms/step - loss: 0.2316 - categorical_accuracy: 0.8920\n",
      "Epoch 11/15\n",
      "5982/5982 [==============================] - 50s 8ms/step - loss: 0.2233 - categorical_accuracy: 0.8954\n",
      "Epoch 12/15\n",
      "5982/5982 [==============================] - 49s 8ms/step - loss: 0.2152 - categorical_accuracy: 0.8994\n",
      "Epoch 13/15\n",
      "5982/5982 [==============================] - 49s 8ms/step - loss: 0.2092 - categorical_accuracy: 0.9028\n",
      "Epoch 14/15\n",
      "5982/5982 [==============================] - 52s 9ms/step - loss: 0.2026 - categorical_accuracy: 0.9054\n",
      "Epoch 15/15\n",
      "5982/5982 [==============================] - 52s 9ms/step - loss: 0.1982 - categorical_accuracy: 0.9081\n",
      "4259/4259 [==============================] - 14s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.882046\n",
      "Precision: 0.902582\n",
      "Recall: 0.932468\n",
      "F1 score: 0.917282\n",
      "Cohens kappa: 0.711985\n",
      "ROC AUC: 0.950734\n",
      "\\Confusion Matrix\n",
      "[[31077  9620]\n",
      " [ 6455 89130]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.881965\n",
      "Precision: 0.824790\n",
      "Recall: 0.764988\n",
      "F1 score: 0.793764\n",
      "Cohens kappa: 0.711251\n",
      "ROC AUC: 0.950569\n",
      "\\Confusion Matrix\n",
      "[[89240  6576]\n",
      " [ 9510 30956]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8820056940755199\n",
      "precision:  0.8636858957149814\n",
      "recall:  0.8487281873088598\n",
      "f1_score:  0.8555229778419764\n",
      "cohen_kappa_score:  0.711618375735162\n",
      "roc_auc_score:  0.9506512777164644\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 15, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ab95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/15\n",
      " 221/5982 [>.............................] - ETA: 46s - loss: 0.6351 - categorical_accuracy: 0.6499"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mCategoricalAccuracy()])\n\u001b[1;32m     13\u001b[0m           \u001b[38;5;66;03m#loss='binary_crossentropy',loss='categorical_crossentropy',\u001b[39;00m\n\u001b[1;32m     14\u001b[0m           \u001b[38;5;66;03m#loss='binary_crossentropy',  sparse_categorical_crossentropy     \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, batch_size=batch_size, validation_split=0.1\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# evaluate model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# predict\u001b[39;00m\n\u001b[1;32m     22\u001b[0m yhat_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_data)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 15, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4a52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/100\n",
      "6896/6896 [==============================] - 53s 7ms/step - loss: 0.2948 - categorical_accuracy: 0.8796\n",
      "Epoch 2/100\n",
      "6896/6896 [==============================] - 50s 7ms/step - loss: 0.2989 - categorical_accuracy: 0.8755\n",
      "Epoch 3/100\n",
      "6896/6896 [==============================] - 49s 7ms/step - loss: 0.3014 - categorical_accuracy: 0.8727\n",
      "Epoch 4/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.3000 - categorical_accuracy: 0.8781\n",
      "Epoch 5/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2947 - categorical_accuracy: 0.8804\n",
      "Epoch 6/100\n",
      "6896/6896 [==============================] - 64s 9ms/step - loss: 0.2932 - categorical_accuracy: 0.8833\n",
      "Epoch 7/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2925 - categorical_accuracy: 0.8837\n",
      "Epoch 8/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2858 - categorical_accuracy: 0.8883\n",
      "Epoch 9/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2845 - categorical_accuracy: 0.8886\n",
      "Epoch 10/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2878 - categorical_accuracy: 0.8902\n",
      "Epoch 11/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2861 - categorical_accuracy: 0.8886\n",
      "Epoch 12/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2779 - categorical_accuracy: 0.8916\n",
      "Epoch 13/100\n",
      "6896/6896 [==============================] - 72s 10ms/step - loss: 0.2745 - categorical_accuracy: 0.8918\n",
      "Epoch 14/100\n",
      "6896/6896 [==============================] - 71s 10ms/step - loss: 0.2692 - categorical_accuracy: 0.8938\n",
      "Epoch 15/100\n",
      "6896/6896 [==============================] - 72s 10ms/step - loss: 0.2650 - categorical_accuracy: 0.8957\n",
      "Epoch 16/100\n",
      "6896/6896 [==============================] - 70s 10ms/step - loss: 0.2588 - categorical_accuracy: 0.8977\n",
      "Epoch 17/100\n",
      "6896/6896 [==============================] - 69s 10ms/step - loss: 0.2539 - categorical_accuracy: 0.8988\n",
      "Epoch 18/100\n",
      "6896/6896 [==============================] - 69s 10ms/step - loss: 0.2491 - categorical_accuracy: 0.8996\n",
      "Epoch 19/100\n",
      "6896/6896 [==============================] - 70s 10ms/step - loss: 0.2473 - categorical_accuracy: 0.8992\n",
      "Epoch 20/100\n",
      "6896/6896 [==============================] - 69s 10ms/step - loss: 0.2589 - categorical_accuracy: 0.8970\n",
      "Epoch 21/100\n",
      "6896/6896 [==============================] - 68s 10ms/step - loss: 0.2454 - categorical_accuracy: 0.9026\n",
      "Epoch 22/100\n",
      "6896/6896 [==============================] - 68s 10ms/step - loss: 0.2429 - categorical_accuracy: 0.9031\n",
      "Epoch 23/100\n",
      "6896/6896 [==============================] - 68s 10ms/step - loss: 0.2552 - categorical_accuracy: 0.9012\n",
      "Epoch 24/100\n",
      "6896/6896 [==============================] - 68s 10ms/step - loss: 0.2408 - categorical_accuracy: 0.9023\n",
      "Epoch 25/100\n",
      "6896/6896 [==============================] - 72s 10ms/step - loss: 0.2506 - categorical_accuracy: 0.8997\n",
      "Epoch 26/100\n",
      "6896/6896 [==============================] - 72s 11ms/step - loss: 0.2393 - categorical_accuracy: 0.9029\n",
      "Epoch 27/100\n",
      "6896/6896 [==============================] - 73s 11ms/step - loss: 0.2365 - categorical_accuracy: 0.9056\n",
      "Epoch 28/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2337 - categorical_accuracy: 0.9067\n",
      "Epoch 29/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2336 - categorical_accuracy: 0.9069\n",
      "Epoch 30/100\n",
      "6896/6896 [==============================] - 61s 9ms/step - loss: 0.2291 - categorical_accuracy: 0.9065\n",
      "Epoch 31/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2295 - categorical_accuracy: 0.9077\n",
      "Epoch 32/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2261 - categorical_accuracy: 0.9081\n",
      "Epoch 33/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2282 - categorical_accuracy: 0.9078\n",
      "Epoch 34/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2248 - categorical_accuracy: 0.9092\n",
      "Epoch 35/100\n",
      "6896/6896 [==============================] - 63s 9ms/step - loss: 0.2243 - categorical_accuracy: 0.9103\n",
      "Epoch 36/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2276 - categorical_accuracy: 0.9088\n",
      "Epoch 37/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2285 - categorical_accuracy: 0.9055\n",
      "Epoch 38/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2235 - categorical_accuracy: 0.9090\n",
      "Epoch 39/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2281 - categorical_accuracy: 0.9069\n",
      "Epoch 40/100\n",
      "6896/6896 [==============================] - 61s 9ms/step - loss: 0.2225 - categorical_accuracy: 0.9088\n",
      "Epoch 41/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2257 - categorical_accuracy: 0.9073\n",
      "Epoch 42/100\n",
      "6896/6896 [==============================] - 62s 9ms/step - loss: 0.2224 - categorical_accuracy: 0.9084\n",
      "Epoch 43/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2217 - categorical_accuracy: 0.9096\n",
      "Epoch 44/100\n",
      "6896/6896 [==============================] - 61s 9ms/step - loss: 0.2274 - categorical_accuracy: 0.9063\n",
      "Epoch 45/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2167 - categorical_accuracy: 0.9106\n",
      "Epoch 46/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2158 - categorical_accuracy: 0.9117\n",
      "Epoch 47/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2268 - categorical_accuracy: 0.9076\n",
      "Epoch 48/100\n",
      "6896/6896 [==============================] - 60s 9ms/step - loss: 0.2189 - categorical_accuracy: 0.9121\n",
      "Epoch 49/100\n",
      "6896/6896 [==============================] - 62s 9ms/step - loss: 0.2146 - categorical_accuracy: 0.9125\n",
      "Epoch 50/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2140 - categorical_accuracy: 0.9131\n",
      "Epoch 51/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2109 - categorical_accuracy: 0.9148\n",
      "Epoch 52/100\n",
      "6896/6896 [==============================] - 61s 9ms/step - loss: 0.2121 - categorical_accuracy: 0.9127\n",
      "Epoch 53/100\n",
      "6896/6896 [==============================] - 57s 8ms/step - loss: 0.2151 - categorical_accuracy: 0.9090\n",
      "Epoch 54/100\n",
      "6896/6896 [==============================] - 55s 8ms/step - loss: 0.2140 - categorical_accuracy: 0.9128\n",
      "Epoch 55/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.2125 - categorical_accuracy: 0.9123\n",
      "Epoch 56/100\n",
      "6896/6896 [==============================] - 54s 8ms/step - loss: 0.2082 - categorical_accuracy: 0.9164\n",
      "Epoch 57/100\n",
      "6896/6896 [==============================] - 53s 8ms/step - loss: 0.2127 - categorical_accuracy: 0.9121\n",
      "Epoch 58/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.2028 - categorical_accuracy: 0.9168\n",
      "Epoch 59/100\n",
      "6896/6896 [==============================] - 54s 8ms/step - loss: 0.2173 - categorical_accuracy: 0.9117\n",
      "Epoch 60/100\n",
      "6896/6896 [==============================] - 53s 8ms/step - loss: 0.2173 - categorical_accuracy: 0.9096\n",
      "Epoch 61/100\n",
      "6896/6896 [==============================] - 54s 8ms/step - loss: 0.2165 - categorical_accuracy: 0.9083\n",
      "Epoch 62/100\n",
      "6896/6896 [==============================] - 54s 8ms/step - loss: 0.2100 - categorical_accuracy: 0.9135\n",
      "Epoch 63/100\n",
      "6896/6896 [==============================] - 54s 8ms/step - loss: 0.2065 - categorical_accuracy: 0.9153\n",
      "Epoch 64/100\n",
      "6896/6896 [==============================] - 54s 8ms/step - loss: 0.2063 - categorical_accuracy: 0.9139\n",
      "Epoch 65/100\n",
      "6896/6896 [==============================] - 55s 8ms/step - loss: 0.2071 - categorical_accuracy: 0.9131\n",
      "Epoch 66/100\n",
      "6896/6896 [==============================] - 52s 8ms/step - loss: 0.2032 - categorical_accuracy: 0.9150\n",
      "Epoch 67/100\n",
      "6896/6896 [==============================] - 53s 8ms/step - loss: 0.2054 - categorical_accuracy: 0.9143\n",
      "Epoch 68/100\n",
      "6896/6896 [==============================] - 51s 7ms/step - loss: 0.2054 - categorical_accuracy: 0.9113\n",
      "Epoch 69/100\n",
      "6896/6896 [==============================] - 49s 7ms/step - loss: 0.2058 - categorical_accuracy: 0.9148\n",
      "Epoch 70/100\n",
      "6896/6896 [==============================] - 49s 7ms/step - loss: 0.2049 - categorical_accuracy: 0.9147\n",
      "Epoch 71/100\n",
      "6896/6896 [==============================] - 48s 7ms/step - loss: 0.2010 - categorical_accuracy: 0.9148\n",
      "Epoch 72/100\n",
      "6896/6896 [==============================] - 48s 7ms/step - loss: 0.2035 - categorical_accuracy: 0.9142\n",
      "Epoch 73/100\n",
      "6896/6896 [==============================] - 49s 7ms/step - loss: 0.2139 - categorical_accuracy: 0.9095\n",
      "Epoch 74/100\n",
      "6896/6896 [==============================] - 48s 7ms/step - loss: 0.2169 - categorical_accuracy: 0.9075\n",
      "Epoch 75/100\n",
      "6896/6896 [==============================] - 52s 8ms/step - loss: 0.2030 - categorical_accuracy: 0.9129\n",
      "Epoch 76/100\n",
      "6896/6896 [==============================] - 52s 7ms/step - loss: 0.2172 - categorical_accuracy: 0.9075\n",
      "Epoch 77/100\n",
      "6896/6896 [==============================] - 51s 7ms/step - loss: 0.2116 - categorical_accuracy: 0.9099\n",
      "Epoch 78/100\n",
      "6896/6896 [==============================] - 52s 8ms/step - loss: 0.2125 - categorical_accuracy: 0.9108\n",
      "Epoch 79/100\n",
      "6896/6896 [==============================] - 52s 8ms/step - loss: 0.2086 - categorical_accuracy: 0.9098\n",
      "Epoch 80/100\n",
      "6896/6896 [==============================] - 51s 7ms/step - loss: 0.2023 - categorical_accuracy: 0.9144\n",
      "Epoch 81/100\n",
      "6896/6896 [==============================] - 52s 7ms/step - loss: 0.2153 - categorical_accuracy: 0.9080\n",
      "Epoch 82/100\n",
      "6896/6896 [==============================] - 50s 7ms/step - loss: 0.2043 - categorical_accuracy: 0.9112\n",
      "Epoch 83/100\n",
      "6896/6896 [==============================] - 51s 7ms/step - loss: 0.2015 - categorical_accuracy: 0.9136\n",
      "Epoch 84/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.2011 - categorical_accuracy: 0.9136\n",
      "Epoch 85/100\n",
      "6896/6896 [==============================] - 57s 8ms/step - loss: 0.2054 - categorical_accuracy: 0.9116\n",
      "Epoch 86/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.2009 - categorical_accuracy: 0.9137\n",
      "Epoch 87/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.1931 - categorical_accuracy: 0.9181\n",
      "Epoch 88/100\n",
      "6896/6896 [==============================] - 57s 8ms/step - loss: 0.1973 - categorical_accuracy: 0.9149\n",
      "Epoch 89/100\n",
      "6896/6896 [==============================] - 55s 8ms/step - loss: 0.1957 - categorical_accuracy: 0.9170\n",
      "Epoch 90/100\n",
      "6896/6896 [==============================] - 57s 8ms/step - loss: 0.1966 - categorical_accuracy: 0.9153\n",
      "Epoch 91/100\n",
      "6896/6896 [==============================] - 58s 8ms/step - loss: 0.1940 - categorical_accuracy: 0.9185\n",
      "Epoch 92/100\n",
      "6896/6896 [==============================] - 58s 8ms/step - loss: 0.1978 - categorical_accuracy: 0.9168\n",
      "Epoch 93/100\n",
      "6896/6896 [==============================] - 57s 8ms/step - loss: 0.2001 - categorical_accuracy: 0.9167\n",
      "Epoch 94/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.1938 - categorical_accuracy: 0.9166\n",
      "Epoch 95/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.2005 - categorical_accuracy: 0.9157\n",
      "Epoch 96/100\n",
      "6896/6896 [==============================] - 55s 8ms/step - loss: 0.1947 - categorical_accuracy: 0.9154\n",
      "Epoch 97/100\n",
      "6896/6896 [==============================] - 55s 8ms/step - loss: 0.1979 - categorical_accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "6896/6896 [==============================] - 55s 8ms/step - loss: 0.2032 - categorical_accuracy: 0.9125\n",
      "Epoch 99/100\n",
      "6896/6896 [==============================] - 56s 8ms/step - loss: 0.1978 - categorical_accuracy: 0.9141\n",
      "Epoch 100/100\n",
      "6896/6896 [==============================] - 59s 9ms/step - loss: 0.2073 - categorical_accuracy: 0.9111\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.272685\n",
      "Precision: 0.979019\n",
      "Recall: 0.102880\n",
      "F1 score: 0.186194\n",
      "Cohens kappa: 0.038272\n",
      "ROC AUC: 0.737497\n",
      "\\Confusion Matrix\n",
      "[[25823   243]\n",
      " [98877 11339]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.270953\n",
      "Precision: 0.205180\n",
      "Recall: 0.990630\n",
      "F1 score: 0.339950\n",
      "Cohens kappa: 0.037826\n",
      "ROC AUC: 0.706877\n",
      "\\Confusion Matrix\n",
      "[[11340 99114]\n",
      " [  242 25586]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2718187288123156\n",
      "precision:  0.5920998003566356\n",
      "recall:  0.5467550616729189\n",
      "f1_score:  0.263071788036283\n",
      "cohen_kappa_score:  0.03804903634117718\n",
      "roc_auc_score:  0.7221871440907924\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 100, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b9b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4259 [==============================] - 11s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.272685\n",
      "Precision: 0.979019\n",
      "Recall: 0.102880\n",
      "F1 score: 0.186194\n",
      "Cohens kappa: 0.038272\n",
      "ROC AUC: 0.737497\n",
      "\\Confusion Matrix\n",
      "[[25823   243]\n",
      " [98877 11339]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.270953\n",
      "Precision: 0.205180\n",
      "Recall: 0.990630\n",
      "F1 score: 0.339950\n",
      "Cohens kappa: 0.037826\n",
      "ROC AUC: 0.706877\n",
      "\\Confusion Matrix\n",
      "[[11340 99114]\n",
      " [  242 25586]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2718187288123156\n",
      "precision:  0.5920998003566356\n",
      "recall:  0.5467550616729189\n",
      "f1_score:  0.263071788036283\n",
      "cohen_kappa_score:  0.03804903634117718\n",
      "roc_auc_score:  0.7221871440907924\n"
     ]
    }
   ],
   "source": [
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344dfe42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3350b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
