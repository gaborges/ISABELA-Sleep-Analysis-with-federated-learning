{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc3553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 23:30:41.664756: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 23:30:42.291900: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-13 23:30:43.694523: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-13 23:30:43.696898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-13 23:30:43.696914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "outputMetricFile = \"result1epochsMLP_oversample_smote.csv\"\n",
    "\n",
    "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "np.random.seed(0)\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    results['matrix'] = np.array(matrix,dtype=object)\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    array.append(np.array(matrix,dtype=object))\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "    \n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e68b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 1\n",
    "NUM_EPOCHS = EPOCHS\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "#TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "# outputs\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "# input folder\n",
    "inputFolders = baseFolder\n",
    "\n",
    "            \n",
    "dsTrain = ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "            'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4', \n",
    "            'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "            'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "            'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "            'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "            'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "            'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "\n",
    "\n",
    "# client datasets used on the training process\n",
    "dsTrain =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            #['PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc'], \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            #['rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw'], \n",
    "            #['RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI'], \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "            #['VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is'], \n",
    "            #['Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw'], \n",
    "            #['XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA'], \n",
    "            #['YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw'], \n",
    "            #['ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM'], \n",
    "            #['ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44b239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_numeric.csv\n",
      "initial len:  (17993, 12)\n",
      "final len:  (32472, 10)\n",
      "1   ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_numeric.csv\n",
      "initial len:  (11561, 12)\n",
      "final len:  (16270, 10)\n",
      "2   ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_numeric.csv\n",
      "initial len:  (3383, 12)\n",
      "final len:  (3836, 10)\n",
      "3   ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_numeric.csv\n",
      "initial len:  (19389, 12)\n",
      "final len:  (23236, 10)\n",
      "4   ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_numeric.csv\n",
      "initial len:  (2753, 12)\n",
      "final len:  (4852, 10)\n",
      "5   ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_numeric.csv\n",
      "initial len:  (26567, 12)\n",
      "final len:  (29438, 10)\n",
      "6   ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_numeric.csv\n",
      "initial len:  (24534, 12)\n",
      "final len:  (42884, 10)\n",
      "7   ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_numeric.csv\n",
      "initial len:  (33902, 12)\n",
      "final len:  (45772, 10)\n",
      "8   ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_numeric.csv\n",
      "initial len:  (26440, 12)\n",
      "final len:  (36122, 10)\n",
      "9   ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_numeric.csv\n",
      "initial len:  (24484, 12)\n",
      "final len:  (42222, 10)\n",
      "10   ../data_2019_processed/student_DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA_numeric.csv\n",
      "initial len:  (1712, 12)\n",
      "11   ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_numeric.csv\n",
      "initial len:  (26020, 12)\n",
      "final len:  (29286, 10)\n",
      "12   ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_numeric.csv\n",
      "initial len:  (25932, 12)\n",
      "final len:  (37576, 10)\n",
      "13   ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_numeric.csv\n",
      "initial len:  (31873, 12)\n",
      "final len:  (48514, 10)\n",
      "14   ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_numeric.csv\n",
      "initial len:  (23244, 12)\n",
      "final len:  (39760, 10)\n",
      "15   ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_numeric.csv\n",
      "initial len:  (19595, 12)\n",
      "final len:  (31804, 10)\n",
      "16   ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_numeric.csv\n",
      "initial len:  (21669, 12)\n",
      "final len:  (29054, 10)\n",
      "17   ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_numeric.csv\n",
      "initial len:  (33344, 12)\n",
      "final len:  (51844, 10)\n",
      "18   ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_numeric.csv\n",
      "initial len:  (22059, 12)\n",
      "final len:  (31430, 10)\n",
      "19   ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_numeric.csv\n",
      "initial len:  (12709, 12)\n",
      "final len:  (23464, 10)\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "# load cliend data\n",
    "clientList = []\n",
    "\n",
    "# balancing classes\n",
    "#oversample = RandomOverSampler(sampling_strategy='auto') #minority\n",
    "oversample = SMOTE(random_state = 32)\n",
    "#undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "for i in range(0,len(dsTrain)):\n",
    "    print (i,\" \", str(inputFolders)+\"student_\"+dsTrain[i]+\"_numeric.csv\") #_numeric\n",
    "    # load client data\n",
    "    dataset = pd.read_csv(inputFolders+\"student_\"+dsTrain[i]+\"_numeric.csv\")\n",
    "    \n",
    "    # print(dataset)\n",
    "    y_train = dataset['class'].copy()\n",
    "    \n",
    "    print(\"initial len: \", dataset.shape)\n",
    "    \n",
    "    # does not add datasets that dont have instances from both classes\n",
    "    if y_train.sum() != 0 and (y_train.sum() != len(y_train)):\n",
    "        X_train = dataset\n",
    "        \n",
    "        del X_train['class']\n",
    "        del X_train['timestamp']\n",
    "        del X_train['timestamp_text']\n",
    "        \n",
    "        # do balancing technique\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        #X_train_under, y_train_under = undersample.fit_resample(X_train_under, y_train_under)\n",
    "        \n",
    "        X_train['class'] = y_train\n",
    "        \n",
    "        clientList.append(X_train)\n",
    "        \n",
    "        print(\"final len: \", X_train.shape)\n",
    "        \n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7fdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 12.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>2018-05-15 02:46:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:27</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:28</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136281</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136282</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136283</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136284</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136285</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136286 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "1           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "2           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "3           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "4           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "136281      0.25       1.0   0.007015     0.166667  0.000056         1.0   \n",
       "136282      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136283      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136284      0.25       1.0   0.007016     0.166667  0.000085         1.0   \n",
       "136285      0.50       1.0   0.007016     0.166667  0.000000         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.655565            0.906151     0.115358   \n",
       "1             1.0  0.567296            0.906052     0.116053   \n",
       "2             1.0  0.567296            0.906052     0.116053   \n",
       "3             1.0  0.660604            0.905952     0.116748   \n",
       "4             1.0  0.660604            0.905952     0.116748   \n",
       "...           ...       ...                 ...          ...   \n",
       "136281        1.0  0.000000            0.000099     0.510076   \n",
       "136282        1.0  0.000000            0.000694     0.512856   \n",
       "136283        1.0  0.000000            0.000595     0.513551   \n",
       "136284        1.0  0.000000            0.000595     0.513551   \n",
       "136285        0.0  0.000000            0.000496     0.514246   \n",
       "\n",
       "             timestamp_text   class  \n",
       "0       2018-05-15 02:46:57  asleep  \n",
       "1       2018-05-15 02:47:27  asleep  \n",
       "2       2018-05-15 02:47:57  asleep  \n",
       "3       2018-05-15 02:48:28  asleep  \n",
       "4       2018-05-15 02:48:57  asleep  \n",
       "...                     ...     ...  \n",
       "136281  2018-06-13 12:14:37   awake  \n",
       "136282  2018-06-13 12:18:08   awake  \n",
       "136283  2018-06-13 12:19:08   awake  \n",
       "136284  2018-06-13 12:19:38   awake  \n",
       "136285  2018-06-13 12:20:08   awake  \n",
       "\n",
       "[136286 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7473fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_numerical_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  uint8  \n",
      " 13  asleep              136286 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0830f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float32\n",
      " 1   location            136286 non-null  float32\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float32\n",
      " 4   light               136286 non-null  float32\n",
      " 5   phone_lock          136286 non-null  float32\n",
      " 6   proximity           136286 non-null  float32\n",
      " 7   sound               136286 non-null  float32\n",
      " 8   time_to_next_alarm  136286 non-null  float32\n",
      " 9   minutes_day         136286 non-null  float32\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  float32\n",
      " 13  asleep              136286 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56557625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 23:30:51.080312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 23:30:51.175578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:51.175905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:51.177177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 23:30:51.180549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:51.180874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:51.181182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:53.828775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:53.829286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:53.829310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-13 23:30:53.829668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 23:30:53.829806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3421 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021a0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9357a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                120       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302\n",
      "Trainable params: 302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17708ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    #keras_model = create_keras_model()\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=client_train_dataset.element_spec,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), #BinaryCrossentropy\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58fa47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avg_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),#client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9279e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,12],\n",
      "      float32[12],\n",
      "      float32[12,12],\n",
      "      float32[12],\n",
      "      float32[12,2],\n",
      "      float32[2]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(fed_avg_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c2f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fed_avg_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da066c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Start timestamp: 1678750257.370855 2023-03-13 23:30:57.370855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 23:31:07.536026: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8757827), ('loss', 0.29827476), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.993985 0.0060149743 0.5\n",
      "[[0.03065543 0.96934456]\n",
      " [0.02599379 0.97400624]\n",
      " [0.02599379 0.97400624]\n",
      " ...\n",
      " [0.01624965 0.9837503 ]\n",
      " [0.01624965 0.9837503 ]\n",
      " [0.03163581 0.96836424]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.297808\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[40587     0]\n",
      " [95699     0]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.297808\n",
      "Precision: 0.297808\n",
      "Recall: 1.000000\n",
      "F1 score: 0.458939\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[    0 95699]\n",
      " [    0 40587]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2978075517661389\n",
      "precision:  0.14890377588306944\n",
      "recall:  0.5\n",
      "f1_score:  0.22946973251994368\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n",
      "\n",
      "0 End timestamp: 1678750380.440089 2023-03-13 23:33:00.440089\n",
      "\n",
      "\n",
      "1 Start timestamp: 1678750380.939923 2023-03-13 23:33:00.939923\n",
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.89748365), ('loss', 0.25707585), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.99804413 0.001955866 0.5\n",
      "[[0.01058805 0.989412  ]\n",
      " [0.00945173 0.9905483 ]\n",
      " [0.00945173 0.9905483 ]\n",
      " ...\n",
      " [0.00607742 0.99392253]\n",
      " [0.00607742 0.99392253]\n",
      " [0.01445617 0.98554385]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.297808\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[40587     0]\n",
      " [95699     0]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.297808\n",
      "Precision: 0.297808\n",
      "Recall: 1.000000\n",
      "F1 score: 0.458939\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[    0 95699]\n",
      " [    0 40587]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2978075517661389\n",
      "precision:  0.14890377588306944\n",
      "recall:  0.5\n",
      "f1_score:  0.22946973251994368\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n",
      "\n",
      "1 End timestamp: 1678750487.601192 2023-03-13 23:34:47.601192\n",
      "\n",
      "\n",
      "2 Start timestamp: 1678750488.111558 2023-03-13 23:34:48.111558\n",
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.90285677), ('loss', 0.24735071), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.99815494 0.0018450877 0.5\n",
      "[[0.00872995 0.99127007]\n",
      " [0.00860059 0.9913994 ]\n",
      " [0.00860059 0.9913994 ]\n",
      " ...\n",
      " [0.00696687 0.9930332 ]\n",
      " [0.00696687 0.9930332 ]\n",
      " [0.01711718 0.9828828 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.297910\n",
      "Precision: 0.791667\n",
      "Recall: 0.000199\n",
      "F1 score: 0.000397\n",
      "Cohens kappa: 0.000045\n",
      "ROC AUC: 0.500038\n",
      "\\Confusion Matrix\n",
      "[[40582     5]\n",
      " [95680    19]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.297910\n",
      "Precision: 0.297823\n",
      "Recall: 0.999877\n",
      "F1 score: 0.458945\n",
      "Cohens kappa: 0.000045\n",
      "ROC AUC: 0.500038\n",
      "\\Confusion Matrix\n",
      "[[   19 95680]\n",
      " [    5 40582]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2979102769176585\n",
      "precision:  0.5447449888205564\n",
      "recall:  0.5000376735072823\n",
      "f1_score:  0.22967109031069283\n",
      "cohen_kappa_score:  4.48823715907265e-05\n",
      "roc_auc_score:  0.5000376735072823\n",
      "\n",
      "2 End timestamp: 1678750598.620548 2023-03-13 23:36:38.620548\n",
      "\n",
      "\n",
      "3 Start timestamp: 1678750599.121347 2023-03-13 23:36:39.121347\n",
      "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.90385705), ('loss', 0.24342029), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.99852705 0.0014729132 0.5\n",
      "[[0.00674762 0.99325234]\n",
      " [0.00779185 0.9922082 ]\n",
      " [0.00779185 0.9922082 ]\n",
      " ...\n",
      " [0.00699921 0.99300086]\n",
      " [0.00699921 0.99300086]\n",
      " [0.01837369 0.9816263 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.298160\n",
      "Precision: 0.824324\n",
      "Recall: 0.000637\n",
      "F1 score: 0.001274\n",
      "Cohens kappa: 0.000189\n",
      "ROC AUC: 0.500159\n",
      "\\Confusion Matrix\n",
      "[[40574    13]\n",
      " [95638    61]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.298160\n",
      "Precision: 0.297874\n",
      "Recall: 0.999680\n",
      "F1 score: 0.458984\n",
      "Cohens kappa: 0.000189\n",
      "ROC AUC: 0.500159\n",
      "\\Confusion Matrix\n",
      "[[   61 95638]\n",
      " [   13 40574]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2981597522856346\n",
      "precision:  0.5610991133852556\n",
      "recall:  0.500158557812839\n",
      "f1_score:  0.23012917098284608\n",
      "cohen_kappa_score:  0.00018893793593766084\n",
      "roc_auc_score:  0.5001585578128389\n",
      "\n",
      "3 End timestamp: 1678750709.14996 2023-03-13 23:38:29.149960\n",
      "\n",
      "\n",
      "4 Start timestamp: 1678750709.648716 2023-03-13 23:38:29.648716\n",
      "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.90290844), ('loss', 0.24491264), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.9983424 0.0016575797 0.5\n",
      "[[0.00747521 0.9925248 ]\n",
      " [0.0092564  0.9907436 ]\n",
      " [0.0092564  0.9907436 ]\n",
      " ...\n",
      " [0.00929182 0.99070823]\n",
      " [0.00929182 0.99070823]\n",
      " [0.02479202 0.9752079 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.298996\n",
      "Precision: 0.745455\n",
      "Recall: 0.002571\n",
      "F1 score: 0.005123\n",
      "Cohens kappa: 0.000299\n",
      "ROC AUC: 0.500250\n",
      "\\Confusion Matrix\n",
      "[[40503    84]\n",
      " [95453   246]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.298996\n",
      "Precision: 0.297913\n",
      "Recall: 0.997930\n",
      "F1 score: 0.458846\n",
      "Cohens kappa: 0.000299\n",
      "ROC AUC: 0.500250\n",
      "\\Confusion Matrix\n",
      "[[  246 95453]\n",
      " [   84 40503]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.2989962285194371\n",
      "precision:  0.5216835527002052\n",
      "recall:  0.5002504657849443\n",
      "f1_score:  0.23198458629827748\n",
      "cohen_kappa_score:  0.0002987790398740753\n",
      "roc_auc_score:  0.5002504657849443\n",
      "\n",
      "4 End timestamp: 1678750816.724592 2023-03-13 23:40:16.724592\n",
      "\n",
      "\n",
      "5 Start timestamp: 1678750817.225231 2023-03-13 23:40:17.225231\n",
      "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.90195656), ('loss', 0.24545376), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.9984825 0.0015175369 0.5\n",
      "[[0.00764114 0.99235886]\n",
      " [0.00995566 0.99004436]\n",
      " [0.00995566 0.99004436]\n",
      " ...\n",
      " [0.01060347 0.9893965 ]\n",
      " [0.01060347 0.9893965 ]\n",
      " [0.0285822  0.9714177 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.300743\n",
      "Precision: 0.773224\n",
      "Recall: 0.005914\n",
      "F1 score: 0.011739\n",
      "Cohens kappa: 0.001090\n",
      "ROC AUC: 0.500912\n",
      "\\Confusion Matrix\n",
      "[[40421   166]\n",
      " [95133   566]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.300743\n",
      "Precision: 0.298191\n",
      "Recall: 0.995910\n",
      "F1 score: 0.458962\n",
      "Cohens kappa: 0.001090\n",
      "ROC AUC: 0.500912\n",
      "\\Confusion Matrix\n",
      "[[  566 95133]\n",
      " [  166 40421]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.30074255609527023\n",
      "precision:  0.5357075852496345\n",
      "recall:  0.500912198910306\n",
      "f1_score:  0.23535040901736584\n",
      "cohen_kappa_score:  0.0010900104441886604\n",
      "roc_auc_score:  0.500912198910306\n",
      "\n",
      "5 End timestamp: 1678750925.455479 2023-03-13 23:42:05.455479\n",
      "\n",
      "\n",
      "6 Start timestamp: 1678750925.947026 2023-03-13 23:42:05.947026\n",
      "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.90138304), ('loss', 0.24521911), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.99871945 0.0012806302 0.5\n",
      "[[0.00725456 0.99274546]\n",
      " [0.00996873 0.99003124]\n",
      " [0.00996873 0.99003124]\n",
      " ...\n",
      " [0.0123011  0.9876989 ]\n",
      " [0.0123011  0.9876989 ]\n",
      " [0.03220748 0.9677926 ]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.302826\n",
      "Precision: 0.808108\n",
      "Recall: 0.009373\n",
      "F1 score: 0.018531\n",
      "Cohens kappa: 0.002469\n",
      "ROC AUC: 0.502063\n",
      "\\Confusion Matrix\n",
      "[[40374   213]\n",
      " [94802   897]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.302826\n",
      "Precision: 0.298677\n",
      "Recall: 0.994752\n",
      "F1 score: 0.459414\n",
      "Cohens kappa: 0.002469\n",
      "ROC AUC: 0.502063\n",
      "\\Confusion Matrix\n",
      "[[  897 94802]\n",
      " [  213 40374]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.30282640916895354\n",
      "precision:  0.5533926940493195\n",
      "recall:  0.5020625764435103\n",
      "f1_score:  0.2389727161445302\n",
      "cohen_kappa_score:  0.0024685820176350015\n",
      "roc_auc_score:  0.5020625764435103\n",
      "\n",
      "6 End timestamp: 1678751035.058262 2023-03-13 23:43:55.058262\n",
      "\n",
      "\n",
      "7 Start timestamp: 1678751035.54012 2023-03-13 23:43:55.540120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.90209824), ('loss', 0.24357563), ('num_examples', 599836), ('num_batches', 18755)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.998798 0.0012019841 0.5\n",
      "[[0.00739361 0.9926064 ]\n",
      " [0.01056772 0.98943233]\n",
      " [0.01056772 0.98943233]\n",
      " ...\n",
      " [0.01374384 0.9862562 ]\n",
      " [0.01374384 0.9862562 ]\n",
      " [0.03574455 0.96425545]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.306194\n",
      "Precision: 0.849114\n",
      "Recall: 0.014525\n",
      "F1 score: 0.028561\n",
      "Cohens kappa: 0.005061\n",
      "ROC AUC: 0.504220\n",
      "\\Confusion Matrix\n",
      "[[40340   247]\n",
      " [94309  1390]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.306194\n",
      "Precision: 0.299594\n",
      "Recall: 0.993914\n",
      "F1 score: 0.460408\n",
      "Cohens kappa: 0.005061\n",
      "ROC AUC: 0.504220\n",
      "\\Confusion Matrix\n",
      "[[ 1390 94309]\n",
      " [  247 40340]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.30619432663663176\n",
      "precision:  0.5743539959704186\n",
      "recall:  0.5042195076070461\n",
      "f1_score:  0.2444842700668641\n",
      "cohen_kappa_score:  0.005061416222244097\n",
      "roc_auc_score:  0.5042195076070461\n",
      "\n",
      "7 End timestamp: 1678751144.579752 2023-03-13 23:45:44.579752\n",
      "\n",
      "\n",
      "8 Start timestamp: 1678751145.053341 2023-03-13 23:45:45.053341\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m time_stamp \u001b[38;5;241m=\u001b[39m current_time\u001b[38;5;241m.\u001b[39mtimestamp()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(i,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart timestamp:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_stamp,current_time)\n\u001b[0;32m---> 22\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfed_avg_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_training_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m state \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m     24\u001b[0m metrics \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:135\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    134\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:67\u001b[0m, in \u001b[0;36mExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:223\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roundData = []\n",
    "\n",
    "columns = ['NN_type','units','epochs','batch_size','max_iterations','Users',\n",
    "           'round_iteration','start_time','end_time','round_time_s','round_time_m',\n",
    "           'class','accuracy','precision','recall','f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "           'TP','FP','FN','TN']\n",
    "\n",
    "MAX_ITERATIONS = 120\n",
    "#NUM_EPOCHS\n",
    "#BATCH_SIZE\n",
    "NN_type = 'MLP'\n",
    "UNITS_NUMBER = 12\n",
    "USER_NUMBER = len(dsTrain)\n",
    "\n",
    "generalData = [NN_type,UNITS_NUMBER,NUM_EPOCHS,BATCH_SIZE,MAX_ITERATIONS,USER_NUMBER]\n",
    "\n",
    "for i in range(0,MAX_ITERATIONS):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}, metrics={}'.format(i,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data,verbose=0)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "    \n",
    "    # generate time metrics\n",
    "    current_time2 = datetime.datetime.now()\n",
    "    time_stamp2 = current_time2.timestamp()\n",
    "    processing_time_s = (time_stamp2-time_stamp)\n",
    "    # generate general metrics\n",
    "    rowData = [i,current_time,current_time2,processing_time_s,(processing_time_s)/60]\n",
    "\n",
    "    print('')\n",
    "    print('awake')    \n",
    "    res,resA = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "   \n",
    "    #columns = ['NN_type','units','epochs','batch_size','max_iterations',''Users',\n",
    "    #            round_iteration','start_time','end_time','round_time_s','round_time_m',\n",
    "    #           'class','accuracy','precision','recall','f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "    #           'TP','FP','FN','TN']\n",
    "    # new data\n",
    "    classData = np.concatenate((['awake'], resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res,resA = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    # new data\n",
    "    classData = np.concatenate((['asleep'], resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    resA = showGlobalMetrics(test) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    # new data\n",
    "    classData = np.concatenate((['avg'], resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    print('')\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time2)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMetrics = pd.DataFrame(data=roundData,columns=columns) \n",
    "\n",
    "dataMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc786c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMetrics.to_csv(outputMetricFile, sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
