{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cc3553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "np.random.seed(0)\n",
    "from collections import Counter\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime;\n",
    "  \n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    results['matrix'] = np.array(matrix,dtype=object)\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    array.append(np.array(matrix,dtype=object))\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "    \n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e68b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 3\n",
    "NUM_EPOCHS = EPOCHS\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "#TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "# outputs\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "# input folder\n",
    "inputFolders = baseFolder\n",
    "\n",
    "            \n",
    "dsTrain = ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "            'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4', \n",
    "            'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "            'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "            'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "            'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "            'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "            'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "\n",
    "\n",
    "# client datasets used on the training process\n",
    "dsTrain =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            #['PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc'], \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            #['rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw'], \n",
    "            #['RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI'], \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "            #['VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is'], \n",
    "            #['Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw'], \n",
    "            #['XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA'], \n",
    "            #['YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw'], \n",
    "            #['ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM'], \n",
    "            #['ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44b239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_numeric.csv\n",
      "1   ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_numeric.csv\n",
      "2   ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_numeric.csv\n",
      "3   ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_numeric.csv\n",
      "4   ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_numeric.csv\n",
      "5   ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_numeric.csv\n",
      "6   ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_numeric.csv\n",
      "7   ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_numeric.csv\n",
      "8   ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_numeric.csv\n",
      "9   ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_numeric.csv\n",
      "10   ../data_2019_processed/student_DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA_numeric.csv\n",
      "11   ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_numeric.csv\n",
      "12   ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_numeric.csv\n",
      "13   ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_numeric.csv\n",
      "14   ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_numeric.csv\n",
      "15   ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_numeric.csv\n",
      "16   ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_numeric.csv\n",
      "17   ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_numeric.csv\n",
      "18   ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_numeric.csv\n",
      "19   ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_numeric.csv\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "# load cliend data\n",
    "clientList = []\n",
    "\n",
    "for i in range(0,len(dsTrain)):\n",
    "    print (i,\" \", str(inputFolders)+\"student_\"+dsTrain[i]+\"_numeric.csv\") #_numeric\n",
    "    # load client data\n",
    "    dataset = pd.read_csv(inputFolders+\"student_\"+dsTrain[i]+\"_numeric.csv\")\n",
    "    \n",
    "    # print(dataset)\n",
    "    y_train = dataset['class'].copy()\n",
    "    \n",
    "    # does not add datasets that dont have instances from both classes\n",
    "    if y_train.sum() != 0 and (y_train.sum() != len(y_train)):\n",
    "        clientList.append(dataset)\n",
    "        \n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7fdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 12.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>2018-05-15 02:46:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:27</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:28</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136281</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136282</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136283</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136284</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136285</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136286 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "1           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "2           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "3           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "4           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "136281      0.25       1.0   0.007015     0.166667  0.000056         1.0   \n",
       "136282      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136283      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136284      0.25       1.0   0.007016     0.166667  0.000085         1.0   \n",
       "136285      0.50       1.0   0.007016     0.166667  0.000000         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.655565            0.906151     0.115358   \n",
       "1             1.0  0.567296            0.906052     0.116053   \n",
       "2             1.0  0.567296            0.906052     0.116053   \n",
       "3             1.0  0.660604            0.905952     0.116748   \n",
       "4             1.0  0.660604            0.905952     0.116748   \n",
       "...           ...       ...                 ...          ...   \n",
       "136281        1.0  0.000000            0.000099     0.510076   \n",
       "136282        1.0  0.000000            0.000694     0.512856   \n",
       "136283        1.0  0.000000            0.000595     0.513551   \n",
       "136284        1.0  0.000000            0.000595     0.513551   \n",
       "136285        0.0  0.000000            0.000496     0.514246   \n",
       "\n",
       "             timestamp_text   class  \n",
       "0       2018-05-15 02:46:57  asleep  \n",
       "1       2018-05-15 02:47:27  asleep  \n",
       "2       2018-05-15 02:47:57  asleep  \n",
       "3       2018-05-15 02:48:28  asleep  \n",
       "4       2018-05-15 02:48:57  asleep  \n",
       "...                     ...     ...  \n",
       "136281  2018-06-13 12:14:37   awake  \n",
       "136282  2018-06-13 12:18:08   awake  \n",
       "136283  2018-06-13 12:19:08   awake  \n",
       "136284  2018-06-13 12:19:38   awake  \n",
       "136285  2018-06-13 12:20:08   awake  \n",
       "\n",
       "[136286 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7473fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_numerical_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  uint8  \n",
      " 13  asleep              136286 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0830f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float32\n",
      " 1   location            136286 non-null  float32\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float32\n",
      " 4   light               136286 non-null  float32\n",
      " 5   phone_lock          136286 non-null  float32\n",
      " 6   proximity           136286 non-null  float32\n",
      " 7   sound               136286 non-null  float32\n",
      " 8   time_to_next_alarm  136286 non-null  float32\n",
      " 9   minutes_day         136286 non-null  float32\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  float32\n",
      " 13  asleep              136286 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56557625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 00:09:14.684484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:14.737447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:14.737712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:14.738521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 00:09:14.743941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:14.744209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:14.744443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:16.544367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:16.544791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:16.544810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-06 00:09:16.545118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-06 00:09:16.545398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3160 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021a0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9357a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                120       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302\n",
      "Trainable params: 302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17708ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    #keras_model = create_keras_model()\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=client_train_dataset.element_spec,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), #BinaryCrossentropy\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fa47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avg_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),#client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce9279e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,12],\n",
      "      float32[12],\n",
      "      float32[12,12],\n",
      "      float32[12],\n",
      "      float32[12,2],\n",
      "      float32[2]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(fed_avg_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c2f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fed_avg_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da066c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start timestamp:- 1678061507.960166 2023-03-06 00:11:47.960166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 00:11:57.255875: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8146376), ('loss', 0.4131568), ('num_examples', 573018), ('num_batches', 17912)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "End timestamp:- 1678061618.506554 2023-03-06 00:13:38.506554\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"Start timestamp:-\", time_stamp,current_time)\n",
    "\n",
    "result = fed_avg_process.next(state, federated_training_data[0:10])\n",
    "state = result.state\n",
    "metrics = result.metrics\n",
    "print('round  1, metrics={}'.format(metrics))\n",
    "\n",
    "print()\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp2 = current_time.timestamp()\n",
    "print(\"End timestamp:-\", time_stamp2,current_time,(time_stamp2-time_stamp)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95aaa901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95845366 0.041546356 0.5\n",
      "[[0.9486743  0.05132568]\n",
      " [0.94928086 0.05071909]\n",
      " [0.94928086 0.05071909]\n",
      " ...\n",
      " [0.7987898  0.20121017]\n",
      " [0.7987894  0.20121063]\n",
      " [0.72438747 0.27561256]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.702192\n",
      "Precision: 0.702192\n",
      "Recall: 1.000000\n",
      "F1 score: 0.825045\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[    0 40587]\n",
      " [    0 95699]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.702192\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[95699     0]\n",
      " [40587     0]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7021924482338612\n",
      "precision:  0.3510962241169306\n",
      "recall:  0.5\n",
      "f1_score:  0.41252236135957066\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#def keras_evaluate(state, round_num):\n",
    "    # Take our global model weights and push them back into a Keras model to\n",
    "    # use its standard `.evaluate()` method.\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "keras_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# get neural network weights\n",
    "weights = fed_avg_process.get_model_weights(state)\n",
    "weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "#tttt.model.assign_weights_to(keras_model)\n",
    "yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "maxX = yhat_probs.max()\n",
    "minX = yhat_probs.min()\n",
    "avgX = yhat_probs.mean()\n",
    "\n",
    "print(maxX,minX,avgX)\n",
    "print(yhat_probs)\n",
    "# predict crisp classes for test set deprecated\n",
    "#printMetrics(y_test,yhat_probs)\n",
    "test = list()\n",
    "\n",
    "xx = yhat_probs.round()\n",
    "\n",
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d310c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start timestamp:- 1678061619.256476 2023-03-06 00:13:39.256476\n",
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.86395466), ('loss', 0.32851), ('num_examples', 649335), ('num_batches', 20298)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "End timestamp:- 1678061735.205267 2023-03-06 00:15:35.205267\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "time_stamp = current_time.timestamp()\n",
    "print(\"Start timestamp:-\", time_stamp,current_time)\n",
    "print()\n",
    "\n",
    "result = fed_avg_process.next(state, federated_training_data[10:19])\n",
    "state = result.state\n",
    "metrics = result.metrics\n",
    "print('round  2, metrics={}'.format(metrics))\n",
    "\n",
    "print()\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp2 = current_time.timestamp()\n",
    "print(\"End timestamp:-\", time_stamp2,current_time,(time_stamp2-time_stamp)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19cf5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98951334 0.010486656 0.5\n",
      "[[0.90594435 0.09405568]\n",
      " [0.91500723 0.08499272]\n",
      " [0.91500723 0.08499272]\n",
      " ...\n",
      " [0.7773878  0.2226122 ]\n",
      " [0.7773866  0.22261341]\n",
      " [0.79301894 0.20698111]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.707189\n",
      "Precision: 0.723385\n",
      "Recall: 0.943970\n",
      "F1 score: 0.819086\n",
      "Cohens kappa: 0.117105\n",
      "ROC AUC: 0.546430\n",
      "\\Confusion Matrix\n",
      "[[ 6043 34544]\n",
      " [ 5362 90337]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.707189\n",
      "Precision: 0.529855\n",
      "Recall: 0.148890\n",
      "F1 score: 0.232459\n",
      "Cohens kappa: 0.117105\n",
      "ROC AUC: 0.546430\n",
      "\\Confusion Matrix\n",
      "[[90337  5362]\n",
      " [34544  6043]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7071892931042073\n",
      "precision:  0.6266199944047741\n",
      "recall:  0.5464300975551518\n",
      "f1_score:  0.5257724428502786\n",
      "cohen_kappa_score:  0.11710455105472517\n",
      "roc_auc_score:  0.5464300975551518\n"
     ]
    }
   ],
   "source": [
    "#def keras_evaluate(state, round_num):\n",
    "    # Take our global model weights and push them back into a Keras model to\n",
    "    # use its standard `.evaluate()` method.\n",
    "keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "keras_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# get neural network weights\n",
    "weights = fed_avg_process.get_model_weights(state)\n",
    "weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "#tttt.model.assign_weights_to(keras_model)\n",
    "yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "maxX = yhat_probs.max()\n",
    "minX = yhat_probs.min()\n",
    "avgX = yhat_probs.mean()\n",
    "print('')\n",
    "print(maxX,minX,avgX)\n",
    "print(yhat_probs)\n",
    "# predict crisp classes for test set deprecated\n",
    "#printMetrics(y_test,yhat_probs)\n",
    "test = list()\n",
    "\n",
    "xx = yhat_probs.round()\n",
    "\n",
    "y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "print('')\n",
    "print('awake')\n",
    "res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb906d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Start timestamp:- 1678061837.315784 2023-03-06 00:17:17.315784\n",
      "\n",
      "round  2-4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8587994), ('loss', 0.33336335), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "0.9974726 0.0025274458 0.5\n",
      "[[0.9210523  0.07894767]\n",
      " [0.9338049  0.06619504]\n",
      " [0.9338049  0.06619504]\n",
      " ...\n",
      " [0.8762232  0.12377678]\n",
      " [0.8762223  0.12377768]\n",
      " [0.8615501  0.13844992]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.718966\n",
      "Precision: 0.735744\n",
      "Recall: 0.935935\n",
      "F1 score: 0.823852\n",
      "Cohens kappa: 0.175791\n",
      "ROC AUC: 0.571658\n",
      "\\Confusion Matrix\n",
      "[[ 8417 32170]\n",
      " [ 6131 89568]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.718966\n",
      "Precision: 0.578568\n",
      "Recall: 0.207382\n",
      "F1 score: 0.305323\n",
      "Cohens kappa: 0.175791\n",
      "ROC AUC: 0.571658\n",
      "\\Confusion Matrix\n",
      "[[89568  6131]\n",
      " [32170  8417]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7189659979748471\n",
      "precision:  0.6571557377264299\n",
      "recall:  0.5716581093527933\n",
      "f1_score:  0.5645878617905158\n",
      "cohen_kappa_score:  0.17579068157169675\n",
      "roc_auc_score:  0.5716581093527933\n",
      "\n",
      "0 End timestamp: 1678062045.85691 2023-03-06 00:20:45.856910\n",
      "\n",
      "\n",
      "1 Start timestamp:- 1678062045.856942 2023-03-06 00:20:45.856942\n",
      "\n",
      "round  4-6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8601762), ('loss', 0.32814074), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "0.9986525 0.0013474694 0.5\n",
      "[[0.9219005  0.07809948]\n",
      " [0.93717235 0.06282762]\n",
      " [0.93717235 0.06282762]\n",
      " ...\n",
      " [0.9045629  0.09543709]\n",
      " [0.9045621  0.09543789]\n",
      " [0.9071769  0.09282304]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.723523\n",
      "Precision: 0.743056\n",
      "Recall: 0.926718\n",
      "F1 score: 0.824787\n",
      "Cohens kappa: 0.205641\n",
      "ROC AUC: 0.585566\n",
      "\\Confusion Matrix\n",
      "[[ 9920 30667]\n",
      " [ 7013 88686]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.723523\n",
      "Precision: 0.585838\n",
      "Recall: 0.244413\n",
      "F1 score: 0.344924\n",
      "Cohens kappa: 0.205641\n",
      "ROC AUC: 0.585566\n",
      "\\Confusion Matrix\n",
      "[[88686  7013]\n",
      " [30667  9920]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7235225921958235\n",
      "precision:  0.6644473079261048\n",
      "recall:  0.5855656916450995\n",
      "f1_score:  0.5848550340588453\n",
      "cohen_kappa_score:  0.20564061699043712\n",
      "roc_auc_score:  0.5855656916450995\n",
      "\n",
      "1 End timestamp: 1678062256.211811 2023-03-06 00:24:16.211811\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:-\", time_stamp,current_time)\n",
    "    print()\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "    \n",
    "    print('')\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp2 = current_time.timestamp()\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time,(time_stamp2-time_stamp)/60)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a32b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Start timestamp:- 1678062576.639819 2023-03-06 00:29:36.639819\n",
      "\n",
      "round  6-8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.860011), ('loss', 0.32768506), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06540baf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06540baf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9989016 0.0010984245 0.5\n",
      "[[0.88587844 0.11412158]\n",
      " [0.9117539  0.08824608]\n",
      " [0.9117539  0.08824608]\n",
      " ...\n",
      " [0.89950615 0.10049383]\n",
      " [0.89950544 0.10049457]\n",
      " [0.9243849  0.07561514]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.722569\n",
      "Precision: 0.747569\n",
      "Recall: 0.913301\n",
      "F1 score: 0.822166\n",
      "Cohens kappa: 0.219130\n",
      "ROC AUC: 0.593074\n",
      "\\Confusion Matrix\n",
      "[[11074 29513]\n",
      " [ 8297 87402]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.722569\n",
      "Precision: 0.571679\n",
      "Recall: 0.272846\n",
      "F1 score: 0.369392\n",
      "Cohens kappa: 0.219130\n",
      "ROC AUC: 0.593074\n",
      "\\Confusion Matrix\n",
      "[[87402  8297]\n",
      " [29513 11074]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7225687157888558\n",
      "precision:  0.6596240304821817\n",
      "recall:  0.5930735322968909\n",
      "f1_score:  0.5957789493097192\n",
      "cohen_kappa_score:  0.2191298092256907\n",
      "roc_auc_score:  0.593073532296891\n",
      "\n",
      "2 End timestamp: 1678062777.951431 2023-03-06 00:32:57.951431 3.355193535486857\n",
      "\n",
      "\n",
      "3 Start timestamp:- 1678062777.951463 2023-03-06 00:32:57.951463\n",
      "\n",
      "round  8-10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8627884), ('loss', 0.32599446), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f076fa905e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f076fa905e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9992193 0.0007806974 0.5\n",
      "[[0.86428344 0.13571654]\n",
      " [0.8939811  0.1060189 ]\n",
      " [0.8939811  0.1060189 ]\n",
      " ...\n",
      " [0.9152242  0.08477583]\n",
      " [0.91522336 0.08477661]\n",
      " [0.9368261  0.06317391]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.725313\n",
      "Precision: 0.748530\n",
      "Recall: 0.916823\n",
      "F1 score: 0.824173\n",
      "Cohens kappa: 0.224912\n",
      "ROC AUC: 0.595290\n",
      "\\Confusion Matrix\n",
      "[[11111 29476]\n",
      " [ 7960 87739]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.725313\n",
      "Precision: 0.582612\n",
      "Recall: 0.273758\n",
      "F1 score: 0.372490\n",
      "Cohens kappa: 0.224912\n",
      "ROC AUC: 0.595290\n",
      "\\Confusion Matrix\n",
      "[[87739  7960]\n",
      " [29476 11111]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7253129448365936\n",
      "precision:  0.6655714107648298\n",
      "recall:  0.5952900722230837\n",
      "f1_score:  0.5983314995955701\n",
      "cohen_kappa_score:  0.22491187978140337\n",
      "roc_auc_score:  0.5952900722230838\n",
      "\n",
      "3 End timestamp: 1678062983.02558 2023-03-06 00:36:23.025580 3.4179019490877787\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,4):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:-\", time_stamp,current_time)\n",
    "    print()\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "    \n",
    "    print('')\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp2 = current_time.timestamp()\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time,(time_stamp2-time_stamp)/60)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a74e0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Start timestamp:- 1678063108.540883 2023-03-06 00:38:28.540883\n",
      "\n",
      "round  10-12, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8670155), ('loss', 0.317863), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.9992848 0.0007152331 0.5\n",
      "[[0.8287252  0.17127475]\n",
      " [0.87183285 0.12816717]\n",
      " [0.87183285 0.12816717]\n",
      " ...\n",
      " [0.90208167 0.09791835]\n",
      " [0.9020807  0.09791932]\n",
      " [0.9374103  0.06258968]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.722356\n",
      "Precision: 0.751521\n",
      "Recall: 0.903249\n",
      "F1 score: 0.820429\n",
      "Cohens kappa: 0.230706\n",
      "ROC AUC: 0.599541\n",
      "\\Confusion Matrix\n",
      "[[12007 28580]\n",
      " [ 9259 86440]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.722356\n",
      "Precision: 0.564610\n",
      "Recall: 0.295834\n",
      "F1 score: 0.388243\n",
      "Cohens kappa: 0.230706\n",
      "ROC AUC: 0.599541\n",
      "\\Confusion Matrix\n",
      "[[86440  9259]\n",
      " [28580 12007]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7223559279749938\n",
      "precision:  0.6580658251968757\n",
      "recall:  0.5995411845478102\n",
      "f1_score:  0.6043360973788228\n",
      "cohen_kappa_score:  0.23070588037478557\n",
      "roc_auc_score:  0.5995411845478102\n",
      "\n",
      "4 End timestamp: 1678063312.985169 2023-03-06 00:41:52.985169 3.4074047644933065\n",
      "\n",
      "\n",
      "5 Start timestamp:- 1678063312.985203 2023-03-06 00:41:52.985203\n",
      "\n",
      "round  12-14, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.86561984), ('loss', 0.31582877), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.99910957 0.0008904622 0.5\n",
      "[[0.78169715 0.21830282]\n",
      " [0.841596   0.15840401]\n",
      " [0.841596   0.15840401]\n",
      " ...\n",
      " [0.86811984 0.1318802 ]\n",
      " [0.8681183  0.13188171]\n",
      " [0.9395601  0.06043992]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.716581\n",
      "Precision: 0.751456\n",
      "Recall: 0.891117\n",
      "F1 score: 0.815349\n",
      "Cohens kappa: 0.224492\n",
      "ROC AUC: 0.598083\n",
      "\\Confusion Matrix\n",
      "[[12381 28206]\n",
      " [10420 85279]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.716581\n",
      "Precision: 0.543002\n",
      "Recall: 0.305048\n",
      "F1 score: 0.390642\n",
      "Cohens kappa: 0.224492\n",
      "ROC AUC: 0.598083\n",
      "\\Confusion Matrix\n",
      "[[85279 10420]\n",
      " [28206 12381]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7165813069574277\n",
      "precision:  0.6472293197341368\n",
      "recall:  0.598082677043955\n",
      "f1_score:  0.6029954640659483\n",
      "cohen_kappa_score:  0.22449243503456273\n",
      "roc_auc_score:  0.5980826770439549\n",
      "\n",
      "5 End timestamp: 1678063516.554237 2023-03-06 00:45:16.554237 3.392817231019338\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,6):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:-\", time_stamp,current_time)\n",
    "    print()\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "    \n",
    "    print('')\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp2 = current_time.timestamp()\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time,(time_stamp2-time_stamp)/60)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85cfd056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Start timestamp:- 1678063571.816222 2023-03-06 00:46:11.816222\n",
      "\n",
      "round  14-16, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8728158), ('loss', 0.30565062), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.9991793 0.00082062965 0.5\n",
      "[[0.7890901  0.21090987]\n",
      " [0.8536053  0.14639471]\n",
      " [0.8536053  0.14639471]\n",
      " ...\n",
      " [0.8573064  0.14269355]\n",
      " [0.8573049  0.14269519]\n",
      " [0.9381073  0.06189271]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.712692\n",
      "Precision: 0.746755\n",
      "Recall: 0.894032\n",
      "F1 score: 0.813784\n",
      "Cohens kappa: 0.206845\n",
      "ROC AUC: 0.589574\n",
      "\\Confusion Matrix\n",
      "[[11572 29015]\n",
      " [10141 85558]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.712692\n",
      "Precision: 0.532953\n",
      "Recall: 0.285116\n",
      "F1 score: 0.371493\n",
      "Cohens kappa: 0.206845\n",
      "ROC AUC: 0.589574\n",
      "\\Confusion Matrix\n",
      "[[85558 10141]\n",
      " [29015 11572]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7126924262213287\n",
      "precision:  0.639853976395349\n",
      "recall:  0.5895741271771703\n",
      "f1_score:  0.5926384140099024\n",
      "cohen_kappa_score:  0.206845151704107\n",
      "roc_auc_score:  0.5895741271771702\n",
      "\n",
      "6 End timestamp: 1678063778.283611 2023-03-06 00:49:38.283611 3.4411231517791747\n",
      "\n",
      "\n",
      "7 Start timestamp:- 1678063778.283639 2023-03-06 00:49:38.283639\n",
      "\n",
      "round  16-18, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8784328), ('loss', 0.29789013), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.9991129 0.0008871116 0.5\n",
      "[[0.8234081  0.17659181]\n",
      " [0.88858145 0.11141855]\n",
      " [0.88858145 0.11141855]\n",
      " ...\n",
      " [0.8520885  0.14791147]\n",
      " [0.85208744 0.14791256]\n",
      " [0.9272417  0.07275829]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.708517\n",
      "Precision: 0.744343\n",
      "Recall: 0.890887\n",
      "F1 score: 0.811048\n",
      "Cohens kappa: 0.195537\n",
      "ROC AUC: 0.584700\n",
      "\\Confusion Matrix\n",
      "[[11304 29283]\n",
      " [10442 85257]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.708517\n",
      "Precision: 0.519820\n",
      "Recall: 0.278513\n",
      "F1 score: 0.362697\n",
      "Cohens kappa: 0.195537\n",
      "ROC AUC: 0.584700\n",
      "\\Confusion Matrix\n",
      "[[85257 10442]\n",
      " [29283 11304]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7085173825631392\n",
      "precision:  0.6320811623526965\n",
      "recall:  0.5846999382073279\n",
      "f1_score:  0.5868727524984263\n",
      "cohen_kappa_score:  0.19553678679521236\n",
      "roc_auc_score:  0.5846999382073279\n",
      "\n",
      "7 End timestamp: 1678063985.759944 2023-03-06 00:53:05.759944 3.4579384167989096\n",
      "\n",
      "\n",
      "8 Start timestamp:- 1678063985.759978 2023-03-06 00:53:05.759978\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(i,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart timestamp:-\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_stamp,current_time)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfed_avg_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_training_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m state \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:135\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    134\u001b[0m   arg \u001b[38;5;241m=\u001b[39m function_utils\u001b[38;5;241m.\u001b[39mpack_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_signature\u001b[38;5;241m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:67\u001b[0m, in \u001b[0;36mExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_coro_and_return_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:223\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_loop)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(6,10):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:-\", time_stamp,current_time)\n",
    "    print()\n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}-{}, metrics={}'.format(i*2+2,i*2+4,metrics))\n",
    "\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict_on_batch(X_test_data)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "    \n",
    "    print('')\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "\n",
    "    print('')\n",
    "    print('awake')\n",
    "    res = printMetrics(y_test_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res = printMetrics(y_test_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    showGlobalMetrics(test)\n",
    "    print('')\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp2 = current_time.timestamp()\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time,(time_stamp2-time_stamp)/60)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2ee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
