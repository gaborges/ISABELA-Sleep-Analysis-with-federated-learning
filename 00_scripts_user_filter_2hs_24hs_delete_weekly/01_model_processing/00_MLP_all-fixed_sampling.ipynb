{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0264faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:25:07.482271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 20:25:07.912306: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-13 20:25:08.957228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-13 20:25:08.959668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-13 20:25:08.959683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "outputMetricFile = \"result3epochsLSTM_oversample01_smote.csv\"\n",
    "\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "import datetime;\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ace58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3a8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    results['matrix'] = np.array(matrix,dtype=object)\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    array.append(np.array(matrix,dtype=object))\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "    \n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))\n",
    "    \n",
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94c076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized.csv\")\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "X_train_under = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized_balanced_undersample_nm.csv\")\n",
    "X_train_over = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized_balanced_oversample_smote.csv\")\n",
    "#X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized_balanced_undersample.csv\")\n",
    "\n",
    "#AA = pd.read_csv(baseFolder+\"allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "#X_train, X_test = train_test_split(AA,test_size=0.25)\n",
    "#X_train = pd.read_csv(\"train_temp.csv\")\n",
    "#X_test = pd.read_csv(\"test_temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afaa1b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 407451 entries, 0 to 407450\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            407451 non-null  float64\n",
      " 1   location            407451 non-null  float64\n",
      " 2   timestamp           407451 non-null  float64\n",
      " 3   time_to_next_alarm  407451 non-null  float64\n",
      " 4   sound               407451 non-null  float64\n",
      " 5   proximity           407451 non-null  float64\n",
      " 6   phone_lock          407451 non-null  float64\n",
      " 7   light               407451 non-null  float64\n",
      " 8   day_of_week         407451 non-null  float64\n",
      " 9   minutes_day         407451 non-null  float64\n",
      " 10  timestamp_text      407451 non-null  object \n",
      " 11  class               407451 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 37.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>sound</th>\n",
       "      <th>proximity</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>light</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2018-05-15 14:20:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2018-05-15 14:20:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.982044</td>\n",
       "      <td>0.604408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>2018-05-15 14:21:15</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.982044</td>\n",
       "      <td>0.604408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>2018-05-15 14:21:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.981944</td>\n",
       "      <td>0.601849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599027</td>\n",
       "      <td>2018-05-15 14:22:15</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407446</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549687</td>\n",
       "      <td>2018-06-12 13:11:39</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407447</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550382</td>\n",
       "      <td>2018-06-12 13:12:09</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407448</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.624127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551077</td>\n",
       "      <td>2018-06-12 13:13:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407449</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.992758</td>\n",
       "      <td>0.540295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551772</td>\n",
       "      <td>2018-06-12 13:14:07</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407450</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.581746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562196</td>\n",
       "      <td>2018-06-12 13:29:33</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407451 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  time_to_next_alarm     sound  \\\n",
       "0           0.00       0.0   0.000869            0.982143  0.000000   \n",
       "1           0.00       0.0   0.000869            0.982143  0.000000   \n",
       "2           0.25       0.5   0.000869            0.982044  0.604408   \n",
       "3           0.25       0.5   0.000869            0.982044  0.604408   \n",
       "4           0.25       0.5   0.000869            0.981944  0.601849   \n",
       "...          ...       ...        ...                 ...       ...   \n",
       "407446      0.25       1.0   0.006924            0.992956  0.644370   \n",
       "407447      0.25       1.0   0.006924            0.992956  0.644370   \n",
       "407448      0.25       1.0   0.006924            0.992857  0.624127   \n",
       "407449      0.00       1.0   0.006924            0.992758  0.540295   \n",
       "407450      0.25       0.0   0.006926            0.991171  0.581746   \n",
       "\n",
       "        proximity  phone_lock     light  day_of_week  minutes_day  \\\n",
       "0             1.0         0.0  0.000175          0.0     0.597637   \n",
       "1             1.0         0.0  0.000175          0.0     0.597637   \n",
       "2             1.0         0.0  0.000165          0.0     0.598332   \n",
       "3             1.0         0.0  0.001449          0.0     0.598332   \n",
       "4             1.0         0.0  0.000198          0.0     0.599027   \n",
       "...           ...         ...       ...          ...          ...   \n",
       "407446        1.0         1.0  0.000000          0.0     0.549687   \n",
       "407447        1.0         1.0  0.000000          0.0     0.550382   \n",
       "407448        1.0         1.0  0.000538          0.0     0.551077   \n",
       "407449        0.0         0.0  0.000000          0.0     0.551772   \n",
       "407450        0.0         1.0  0.000005          0.0     0.562196   \n",
       "\n",
       "             timestamp_text  class  \n",
       "0       2018-05-15 14:20:45  awake  \n",
       "1       2018-05-15 14:20:45  awake  \n",
       "2       2018-05-15 14:21:15  awake  \n",
       "3       2018-05-15 14:21:45  awake  \n",
       "4       2018-05-15 14:22:15  awake  \n",
       "...                     ...    ...  \n",
       "407446  2018-06-12 13:11:39  awake  \n",
       "407447  2018-06-12 13:12:09  awake  \n",
       "407448  2018-06-12 13:13:37  awake  \n",
       "407449  2018-06-12 13:14:07  awake  \n",
       "407450  2018-06-12 13:29:33  awake  \n",
       "\n",
       "[407451 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.info())\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aef4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two classes based on the single class\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_train = transform_output_nominal_class_into_one_hot_encoding(X_train)\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_train_under = transform_output_nominal_class_into_one_hot_encoding(X_train_under)\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_train_over = transform_output_nominal_class_into_one_hot_encoding(X_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bb4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity\tlocation\ttimestamp\tday_of_week\tlight\tphone_lock\tproximity\tsound\ttime_to_next_alarm\tminutes_day\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\"light\",\"phone_lock\",\"proximity\",\"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "#inputFeatures = [\"activity\",\"location\",\"day_of_week\",\"light\",\"phone_lock\",\"proximity\",\"sound\", \"minutes_day\"]\n",
    "\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "\n",
    "\n",
    "\n",
    "def create_keras_model(inputFeatures,outputClasses):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(len(inputFeatures),)),\n",
    "        tf.keras.layers.Dense(len(inputFeatures)),\n",
    "        tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.Dense(len(outputClasses), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb47401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "--------------\n",
      "Initializing raw test\n",
      "--------------\n",
      "Batch Size:  32\n",
      "Epochs:  5\n",
      "Input/Features: 9\n",
      "Outputs: 2\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:25:16.888993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:16.970105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:16.970456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:16.972523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 20:25:16.976286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:16.976550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:16.976821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:18.150648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:18.151522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:18.151541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-13 20:25:18.151863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 20:25:18.151920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3421 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   32/12733 [..............................] - ETA: 1:04 - loss: 0.7532 - categorical_accuracy: 0.4404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:25:20.376318: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12733/12733 [==============================] - 77s 6ms/step - loss: 0.3945 - categorical_accuracy: 0.8319\n",
      "Epoch 2/5\n",
      "12733/12733 [==============================] - 77s 6ms/step - loss: 0.3758 - categorical_accuracy: 0.8414\n",
      "Epoch 3/5\n",
      "12733/12733 [==============================] - 77s 6ms/step - loss: 0.3714 - categorical_accuracy: 0.8439\n",
      "Epoch 4/5\n",
      "12733/12733 [==============================] - 77s 6ms/step - loss: 0.3685 - categorical_accuracy: 0.8449\n",
      "Epoch 5/5\n",
      "12733/12733 [==============================] - 75s 6ms/step - loss: 0.3669 - categorical_accuracy: 0.8450\n",
      "{'loss': 0.3871196508407593, 'categorical_accuracy': 0.8360121250152588}\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------\")\n",
    "print(\"--------------\")\n",
    "print(\"Initializing raw test\")\n",
    "print(\"--------------\")\n",
    "print(\"Batch Size: \",BATCH_SIZE)\n",
    "print(\"Epochs: \",EPOCHS)\n",
    "print(\"Input/Features:\",len(inputFeatures))\n",
    "print(\"Outputs:\",len(outputClasses))\n",
    "print(\"--------------\")\n",
    "\n",
    "# selects the data to train and test\n",
    "X_train_data = pd.DataFrame(data=X_train,columns=inputFeatures)\n",
    "y_train_data = pd.DataFrame(data=X_train,columns=outputClasses)\n",
    "# selec test dataset (fixed to all)\n",
    "X_test_data = pd.DataFrame(data=X_test,columns=inputFeatures)\n",
    "y_test_data = pd.DataFrame(data=X_test,columns=outputClasses)\n",
    "\n",
    "# instanciates the model\n",
    "model = create_keras_model(inputFeatures,outputClasses)\n",
    "\n",
    "# compiles the model\n",
    "model.compile(optimizer='adam',\n",
    "             # loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "              #loss='binary_crossentropy',  sparse_categorical_crossentropy         \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "# \n",
    "model.fit(X_train_data, y_train_data, epochs=EPOCHS,batch_size=BATCH_SIZE)\n",
    "\n",
    "results = model.evaluate(X_test_data, y_test_data, return_dict=True,verbose=0)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8669cc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4216/4216 [==============================] - 6s 1ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.836012\n",
      "Precision: 0.868023\n",
      "Recall: 0.941623\n",
      "F1 score: 0.903327\n",
      "Cohens kappa: 0.369169\n",
      "ROC AUC: 0.787335\n",
      "\\Confusion Matrix\n",
      "[[  9422  15713]\n",
      " [  6407 103346]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.836012\n",
      "Precision: 0.595237\n",
      "Recall: 0.374856\n",
      "F1 score: 0.460014\n",
      "Cohens kappa: 0.369169\n",
      "ROC AUC: 0.787335\n",
      "\\Confusion Matrix\n",
      "[[103346   6407]\n",
      " [ 15713   9422]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8360120989265168\n",
      "precision:  0.7316300040141837\n",
      "recall:  0.6582396211950189\n",
      "f1_score:  0.6816702095685439\n",
      "cohen_kappa_score:  0.3691689354090413\n",
      "roc_auc_score:  0.787335269266787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8360120989265168,\n",
       " 0.7316300040141837,\n",
       " 0.6582396211950189,\n",
       " 0.6816702095685439,\n",
       " 0.3691689354090413,\n",
       " 0.787335269266787]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_probs = model.predict(X_test_data)\n",
    "# dataset\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "\n",
    "test = list()\n",
    "print('')\n",
    "print('awake')\n",
    "res,resA = printMetrics(y_test_data['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res,resA = printMetrics(y_test_data['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad19f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "--------------\n",
      "Initializing Undersample test\n",
      "--------------\n",
      "Batch Size:  32\n",
      "Epochs:  5\n",
      "Input/Features: 9\n",
      "Outputs: 2\n",
      "--------------\n",
      "Epoch 1/5\n",
      "4617/4617 [==============================] - 27s 6ms/step - loss: 0.6418 - categorical_accuracy: 0.6277\n",
      "Epoch 2/5\n",
      "4617/4617 [==============================] - 27s 6ms/step - loss: 0.6182 - categorical_accuracy: 0.6571\n",
      "Epoch 3/5\n",
      "4617/4617 [==============================] - 26s 6ms/step - loss: 0.6121 - categorical_accuracy: 0.6628\n",
      "Epoch 4/5\n",
      "4617/4617 [==============================] - 27s 6ms/step - loss: 0.6078 - categorical_accuracy: 0.6671\n",
      "Epoch 5/5\n",
      "4617/4617 [==============================] - 26s 6ms/step - loss: 0.6049 - categorical_accuracy: 0.6695\n",
      "{'loss': 0.6557937264442444, 'categorical_accuracy': 0.6333476901054382}\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------\")\n",
    "print(\"--------------\")\n",
    "print(\"Initializing Undersample test\")\n",
    "print(\"--------------\")\n",
    "print(\"Batch Size: \",BATCH_SIZE)\n",
    "print(\"Epochs: \",EPOCHS)\n",
    "print(\"Input/Features:\",len(inputFeatures))\n",
    "print(\"Outputs:\",len(outputClasses))\n",
    "print(\"--------------\")\n",
    "\n",
    "# selects the data to train and test\n",
    "X_train_data = pd.DataFrame(data=X_train_under,columns=inputFeatures)\n",
    "y_train_data = pd.DataFrame(data=X_train_under,columns=outputClasses)\n",
    "# selec test dataset (fixed to all)\n",
    "X_test_data = pd.DataFrame(data=X_test,columns=inputFeatures)\n",
    "y_test_data = pd.DataFrame(data=X_test,columns=outputClasses)\n",
    "\n",
    "# instanciates the model\n",
    "model = create_keras_model(inputFeatures,outputClasses)\n",
    "\n",
    "# compiles the model\n",
    "model.compile(optimizer='adam',\n",
    "             # loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "              #loss='binary_crossentropy',  sparse_categorical_crossentropy         \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "# \n",
    "model.fit(X_train_data, y_train_data, epochs=EPOCHS,batch_size=BATCH_SIZE)\n",
    "\n",
    "results = model.evaluate(X_test_data, y_test_data, return_dict=True,verbose=0)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54953cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4216/4216 [==============================] - 5s 1ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.633348\n",
      "Precision: 0.915662\n",
      "Recall: 0.605113\n",
      "F1 score: 0.728680\n",
      "Cohens kappa: 0.230283\n",
      "ROC AUC: 0.711646\n",
      "\\Confusion Matrix\n",
      "[[19018  6117]\n",
      " [43340 66413]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.633348\n",
      "Precision: 0.304981\n",
      "Recall: 0.756634\n",
      "F1 score: 0.434732\n",
      "Cohens kappa: 0.230283\n",
      "ROC AUC: 0.711646\n",
      "\\Confusion Matrix\n",
      "[[66413 43340]\n",
      " [ 6117 19018]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.6333476662119685\n",
      "precision:  0.6103217005658944\n",
      "recall:  0.6808737376583984\n",
      "f1_score:  0.5817060253302145\n",
      "cohen_kappa_score:  0.23028255498747197\n",
      "roc_auc_score:  0.7116458715077294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6333476662119685,\n",
       " 0.6103217005658944,\n",
       " 0.6808737376583984,\n",
       " 0.5817060253302145,\n",
       " 0.23028255498747197,\n",
       " 0.7116458715077294]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_probs = model.predict(X_test_data)\n",
    "# dataset\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "\n",
    "test = list()\n",
    "print('')\n",
    "print('awake')\n",
    "res,resA = printMetrics(y_test_data['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res,resA = printMetrics(y_test_data['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea210b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "--------------\n",
      "Initializing Oversample test\n",
      "--------------\n",
      "Batch Size:  32\n",
      "Epochs:  5\n",
      "Input/Features: 9\n",
      "Outputs: 2\n",
      "--------------\n",
      "Epoch 1/5\n",
      "20850/20850 [==============================] - 119s 6ms/step - loss: 0.5512 - categorical_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "20850/20850 [==============================] - 121s 6ms/step - loss: 0.5309 - categorical_accuracy: 0.7426\n",
      "Epoch 3/5\n",
      "20850/20850 [==============================] - 121s 6ms/step - loss: 0.5250 - categorical_accuracy: 0.7458\n",
      "Epoch 4/5\n",
      "20850/20850 [==============================] - 121s 6ms/step - loss: 0.5208 - categorical_accuracy: 0.7485\n",
      "Epoch 5/5\n",
      "20850/20850 [==============================] - 120s 6ms/step - loss: 0.5179 - categorical_accuracy: 0.7501\n",
      "{'loss': 0.47760361433029175, 'categorical_accuracy': 0.8022581934928894}\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------\")\n",
    "print(\"--------------\")\n",
    "print(\"Initializing Oversample test\")\n",
    "print(\"--------------\")\n",
    "print(\"Batch Size: \",BATCH_SIZE)\n",
    "print(\"Epochs: \",EPOCHS)\n",
    "print(\"Input/Features:\",len(inputFeatures))\n",
    "print(\"Outputs:\",len(outputClasses))\n",
    "print(\"--------------\")\n",
    "\n",
    "# selects the data to train and test\n",
    "X_train_data = pd.DataFrame(data=X_train_over,columns=inputFeatures)\n",
    "y_train_data = pd.DataFrame(data=X_train_over,columns=outputClasses)\n",
    "# selec test dataset (fixed to all)\n",
    "X_test_data = pd.DataFrame(data=X_test,columns=inputFeatures)\n",
    "y_test_data = pd.DataFrame(data=X_test,columns=outputClasses)\n",
    "\n",
    "# instanciates the model\n",
    "model = create_keras_model(inputFeatures,outputClasses)\n",
    "\n",
    "# compiles the model\n",
    "model.compile(optimizer='adam',\n",
    "             # loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "              #loss='binary_crossentropy',  sparse_categorical_crossentropy         \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "# \n",
    "model.fit(X_train_data, y_train_data, epochs=EPOCHS,batch_size=BATCH_SIZE)\n",
    "\n",
    "results = model.evaluate(X_test_data, y_test_data, return_dict=True,verbose=0)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e718491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4216/4216 [==============================] - 6s 1ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.802258\n",
      "Precision: 0.922747\n",
      "Recall: 0.826137\n",
      "F1 score: 0.871774\n",
      "Cohens kappa: 0.445597\n",
      "ROC AUC: 0.799008\n",
      "\\Confusion Matrix\n",
      "[[17544  7591]\n",
      " [19082 90671]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.802258\n",
      "Precision: 0.479004\n",
      "Recall: 0.697991\n",
      "F1 score: 0.568126\n",
      "Cohens kappa: 0.445597\n",
      "ROC AUC: 0.799008\n",
      "\\Confusion Matrix\n",
      "[[90671 19082]\n",
      " [ 7591 17544]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.802258169740822\n",
      "precision:  0.700875667581794\n",
      "recall:  0.7620638601935416\n",
      "f1_score:  0.7199495931352058\n",
      "cohen_kappa_score:  0.4455973116938615\n",
      "roc_auc_score:  0.7990079662050198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.802258169740822,\n",
       " 0.700875667581794,\n",
       " 0.7620638601935416,\n",
       " 0.7199495931352058,\n",
       " 0.4455973116938615,\n",
       " 0.7990079662050198]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_probs = model.predict(X_test_data)\n",
    "# dataset\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "\n",
    "test = list()\n",
    "print('')\n",
    "print('awake')\n",
    "res,resA = printMetrics(y_test_data['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res,resA = printMetrics(y_test_data['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43409920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b0c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478f5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
