{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2701ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 21:08:13.075738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-05 21:08:13.680605: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-05 21:08:15.017855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-05 21:08:15.019992: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-03-05 21:08:15.020009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# example of random oversampling to balance the class distribution\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e61842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    return results\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f392d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized.csv\")\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "#X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized_balanced_undersample.csv\")\n",
    "#X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized_balanced_oversample.csv\")\n",
    "\n",
    "#AA = pd.read_csv(baseFolder+\"allData-classification-numeric-normalized.csv\")\n",
    "#X_train, X_test = train_test_split(AA,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413d6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 407451 entries, 0 to 407450\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            407451 non-null  float64\n",
      " 1   location            407451 non-null  float64\n",
      " 2   timestamp           407451 non-null  float64\n",
      " 3   day_of_week         407451 non-null  float64\n",
      " 4   light               407451 non-null  float64\n",
      " 5   phone_lock          407451 non-null  float64\n",
      " 6   proximity           407451 non-null  float64\n",
      " 7   sound               407451 non-null  float64\n",
      " 8   time_to_next_alarm  407451 non-null  float64\n",
      " 9   minutes_day         407451 non-null  float64\n",
      " 10  timestamp_text      407451 non-null  object \n",
      " 11  class               407451 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 37.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2018-05-15 14:20:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2018-05-15 14:20:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604408</td>\n",
       "      <td>0.982044</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>2018-05-15 14:21:15</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604408</td>\n",
       "      <td>0.982044</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>2018-05-15 14:21:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601849</td>\n",
       "      <td>0.981944</td>\n",
       "      <td>0.599027</td>\n",
       "      <td>2018-05-15 14:22:15</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407446</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.549687</td>\n",
       "      <td>2018-06-12 13:11:39</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407447</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.550382</td>\n",
       "      <td>2018-06-12 13:12:09</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407448</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624127</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.551077</td>\n",
       "      <td>2018-06-12 13:13:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407449</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540295</td>\n",
       "      <td>0.992758</td>\n",
       "      <td>0.551772</td>\n",
       "      <td>2018-06-12 13:14:07</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407450</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581746</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.562196</td>\n",
       "      <td>2018-06-12 13:29:33</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407451 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       0.0   0.000869          0.0  0.000175         0.0   \n",
       "1           0.00       0.0   0.000869          0.0  0.000175         0.0   \n",
       "2           0.25       0.5   0.000869          0.0  0.000165         0.0   \n",
       "3           0.25       0.5   0.000869          0.0  0.001449         0.0   \n",
       "4           0.25       0.5   0.000869          0.0  0.000198         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "407446      0.25       1.0   0.006924          0.0  0.000000         1.0   \n",
       "407447      0.25       1.0   0.006924          0.0  0.000000         1.0   \n",
       "407448      0.25       1.0   0.006924          0.0  0.000538         1.0   \n",
       "407449      0.00       1.0   0.006924          0.0  0.000000         0.0   \n",
       "407450      0.25       0.0   0.006926          0.0  0.000005         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.000000            0.982143     0.597637   \n",
       "1             1.0  0.000000            0.982143     0.597637   \n",
       "2             1.0  0.604408            0.982044     0.598332   \n",
       "3             1.0  0.604408            0.982044     0.598332   \n",
       "4             1.0  0.601849            0.981944     0.599027   \n",
       "...           ...       ...                 ...          ...   \n",
       "407446        1.0  0.644370            0.992956     0.549687   \n",
       "407447        1.0  0.644370            0.992956     0.550382   \n",
       "407448        1.0  0.624127            0.992857     0.551077   \n",
       "407449        0.0  0.540295            0.992758     0.551772   \n",
       "407450        0.0  0.581746            0.991171     0.562196   \n",
       "\n",
       "             timestamp_text  class  \n",
       "0       2018-05-15 14:20:45  awake  \n",
       "1       2018-05-15 14:20:45  awake  \n",
       "2       2018-05-15 14:21:15  awake  \n",
       "3       2018-05-15 14:21:45  awake  \n",
       "4       2018-05-15 14:22:15  awake  \n",
       "...                     ...    ...  \n",
       "407446  2018-06-12 13:11:39  awake  \n",
       "407447  2018-06-12 13:12:09  awake  \n",
       "407448  2018-06-12 13:13:37  awake  \n",
       "407449  2018-06-12 13:14:07  awake  \n",
       "407450  2018-06-12 13:29:33  awake  \n",
       "\n",
       "[407451 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.info())\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5feb752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_train = transform_output_nominal_class_into_one_hot_encoding(X_train)\n",
    "\n",
    "\n",
    "# transforms the input data to float32\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "# transforms the input data to float32\n",
    "X_train = transform_data_type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf8855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (407447, 4, 9) (407447, 2)\n",
      "Size:  (136282, 4, 9) (136282, 2)\n"
     ]
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_train_data = pd.DataFrame(data=X_train,columns=inputFeatures)\n",
    "y_train_data = pd.DataFrame(data=X_train,columns=outputClasses)\n",
    "# selec test dataset (fixed to all)\n",
    "X_test_data = pd.DataFrame(data=X_test,columns=inputFeatures)\n",
    "y_test_data = pd.DataFrame(data=X_test,columns=outputClasses)\n",
    "\n",
    "X_train_data, y_train_data = create_dataset_time_series_with_one_output(   #timestamp\n",
    "    X_train_data, \n",
    "    y_train_data, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "X_test_data, y_test_data = create_dataset_time_series_with_one_output(    #timestamp\n",
    "    X_test_data, \n",
    "    y_test_data, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "\n",
    "print(\"shape: \",X_train_data.shape, y_train_data.shape)\n",
    "print(\"Size: \",X_test_data.shape,y_test_data.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7518d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 21:10:53.192509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:53.249916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:53.250193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:53.251760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-05 21:10:53.254000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:53.254307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:53.254629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:54.937096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:54.937461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:54.937475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-05 21:10:54.937773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-05 21:10:54.938316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3421 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# transtorm data to tensor slices\n",
    "test_dataset_series = tf.data.Dataset.from_tensor_slices((X_test_data, y_test_data))\n",
    "train_dataset_series = tf.data.Dataset.from_tensor_slices((X_train_data, y_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de06a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(4, 9), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc486e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client_test_dataset.window(size=4, shift=1, stride=1, drop_remainder=True)\n",
    "#test_dataset_series.batch(BATCH_SIZE) # usado no federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97211c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 4, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch data size\n",
    "#test_dataset_series1 = test_dataset_series.batch(1)\n",
    "#train_dataset_series1 = train_dataset_series.batch(1)\n",
    "\n",
    "test_dataset_series1 = test_dataset_series.batch(BATCH_SIZE)\n",
    "train_dataset_series1 = train_dataset_series.batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset_series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06366f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c846c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 21:10:57.941332: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-03-05 21:11:00.321884: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12733/12733 [==============================] - 93s 7ms/step - loss: 0.5262 - categorical_accuracy: 0.7599\n",
      "Epoch 2/2\n",
      "12733/12733 [==============================] - 90s 7ms/step - loss: 0.4978 - categorical_accuracy: 0.7735\n",
      "4259/4259 [==============================] - 9s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.749695\n",
      "Precision: 0.786232\n",
      "Recall: 0.883277\n",
      "F1 score: 0.831934\n",
      "Cohens kappa: 0.348214\n",
      "ROC AUC: 0.720002\n",
      "\\Confusion Matrix\n",
      "[[17742 22955]\n",
      " [11157 84428]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.750363\n",
      "Precision: 0.611509\n",
      "Recall: 0.436712\n",
      "F1 score: 0.509537\n",
      "Cohens kappa: 0.348296\n",
      "ROC AUC: 0.719740\n",
      "\\Confusion Matrix\n",
      "[[84589 11227]\n",
      " [22794 17672]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7500293509047415\n",
      "precision:  0.6988707532037979\n",
      "recall:  0.6599944832170093\n",
      "f1_score:  0.6707353038765316\n",
      "cohen_kappa_score:  0.3482546841555687\n",
      "roc_auc_score:  0.7198713496952152\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a844945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/7\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.5264 - categorical_accuracy: 0.7589\n",
      "Epoch 2/7\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4966 - categorical_accuracy: 0.7739\n",
      "Epoch 3/7\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.4723 - categorical_accuracy: 0.7835\n",
      "Epoch 4/7\n",
      "12733/12733 [==============================] - 88s 7ms/step - loss: 0.4497 - categorical_accuracy: 0.7925\n",
      "Epoch 5/7\n",
      "12733/12733 [==============================] - 94s 7ms/step - loss: 0.4310 - categorical_accuracy: 0.8000\n",
      "Epoch 6/7\n",
      "12733/12733 [==============================] - 92s 7ms/step - loss: 0.4166 - categorical_accuracy: 0.8059\n",
      "Epoch 7/7\n",
      "12733/12733 [==============================] - 91s 7ms/step - loss: 0.4048 - categorical_accuracy: 0.8112\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.713748\n",
      "Precision: 0.764211\n",
      "Recall: 0.855971\n",
      "F1 score: 0.807493\n",
      "Cohens kappa: 0.256444\n",
      "ROC AUC: 0.688621\n",
      "\\Confusion Matrix\n",
      "[[15453 25244]\n",
      " [13767 81818]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.714357\n",
      "Precision: 0.526318\n",
      "Recall: 0.380047\n",
      "F1 score: 0.441380\n",
      "Cohens kappa: 0.256155\n",
      "ROC AUC: 0.688320\n",
      "\\Confusion Matrix\n",
      "[[81975 13841]\n",
      " [25087 15379]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7140524794176781\n",
      "precision:  0.6452644911107244\n",
      "recall:  0.6180092862081012\n",
      "f1_score:  0.6244363682525507\n",
      "cohen_kappa_score:  0.2562996097284321\n",
      "roc_auc_score:  0.6884704753647537\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 7, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbff1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f152b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/15\n",
      "12733/12733 [==============================] - 90s 7ms/step - loss: 0.5091 - categorical_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.5084 - categorical_accuracy: 0.7726\n",
      "Epoch 3/15\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.5029 - categorical_accuracy: 0.7723\n",
      "Epoch 4/15\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.4869 - categorical_accuracy: 0.7780\n",
      "Epoch 5/15\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4827 - categorical_accuracy: 0.7824\n",
      "Epoch 6/15\n",
      "12733/12733 [==============================] - 91s 7ms/step - loss: 0.4742 - categorical_accuracy: 0.7848\n",
      "Epoch 7/15\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4749 - categorical_accuracy: 0.7842\n",
      "Epoch 8/15\n",
      "12733/12733 [==============================] - 91s 7ms/step - loss: 0.4762 - categorical_accuracy: 0.7850\n",
      "Epoch 9/15\n",
      "12733/12733 [==============================] - 88s 7ms/step - loss: 0.4671 - categorical_accuracy: 0.7900\n",
      "Epoch 10/15\n",
      "12733/12733 [==============================] - 86s 7ms/step - loss: 0.4718 - categorical_accuracy: 0.7906\n",
      "Epoch 11/15\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.4697 - categorical_accuracy: 0.7913\n",
      "Epoch 12/15\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4660 - categorical_accuracy: 0.7925\n",
      "Epoch 13/15\n",
      "12733/12733 [==============================] - 85s 7ms/step - loss: 0.4644 - categorical_accuracy: 0.7945\n",
      "Epoch 14/15\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.4569 - categorical_accuracy: 0.8004\n",
      "Epoch 15/15\n",
      "12733/12733 [==============================] - 88s 7ms/step - loss: 0.4529 - categorical_accuracy: 0.8053\n",
      "4259/4259 [==============================] - 9s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.723720\n",
      "Precision: 0.719868\n",
      "Recall: 0.992195\n",
      "F1 score: 0.834373\n",
      "Cohens kappa: 0.114577\n",
      "ROC AUC: 0.709944\n",
      "\\Confusion Matrix\n",
      "[[ 3791 36906]\n",
      " [  746 94839]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.725224\n",
      "Precision: 0.832709\n",
      "Recall: 0.093362\n",
      "F1 score: 0.167900\n",
      "Cohens kappa: 0.114910\n",
      "ROC AUC: 0.709374\n",
      "\\Confusion Matrix\n",
      "[[95057   759]\n",
      " [36688  3778]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7244720506009598\n",
      "precision:  0.7762883825580158\n",
      "recall:  0.5427788785108164\n",
      "f1_score:  0.501136427901439\n",
      "cohen_kappa_score:  0.1147431134464802\n",
      "roc_auc_score:  0.7096589008182953\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 15, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723e8cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/30\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.5057 - categorical_accuracy: 0.7671\n",
      "Epoch 2/30\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.5090 - categorical_accuracy: 0.7725\n",
      "Epoch 3/30\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4951 - categorical_accuracy: 0.7741\n",
      "Epoch 4/30\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4881 - categorical_accuracy: 0.7774\n",
      "Epoch 5/30\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4884 - categorical_accuracy: 0.7750\n",
      "Epoch 6/30\n",
      "12733/12733 [==============================] - 89s 7ms/step - loss: 0.4795 - categorical_accuracy: 0.7821\n",
      "Epoch 7/30\n",
      "12733/12733 [==============================] - 90s 7ms/step - loss: 0.4731 - categorical_accuracy: 0.7868\n",
      "Epoch 8/30\n",
      "12733/12733 [==============================] - 90s 7ms/step - loss: 0.4688 - categorical_accuracy: 0.7903\n",
      "Epoch 9/30\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.4640 - categorical_accuracy: 0.7960\n",
      "Epoch 10/30\n",
      "12733/12733 [==============================] - 90s 7ms/step - loss: 0.4622 - categorical_accuracy: 0.7950\n",
      "Epoch 11/30\n",
      "12733/12733 [==============================] - 88s 7ms/step - loss: 0.4574 - categorical_accuracy: 0.7975\n",
      "Epoch 12/30\n",
      "12733/12733 [==============================] - 88s 7ms/step - loss: 0.4483 - categorical_accuracy: 0.8031\n",
      "Epoch 13/30\n",
      "12733/12733 [==============================] - 88s 7ms/step - loss: 0.4456 - categorical_accuracy: 0.8038\n",
      "Epoch 14/30\n",
      "12733/12733 [==============================] - 86s 7ms/step - loss: 0.4481 - categorical_accuracy: 0.8029\n",
      "Epoch 15/30\n",
      "12733/12733 [==============================] - 87s 7ms/step - loss: 0.4343 - categorical_accuracy: 0.8070\n",
      "Epoch 16/30\n",
      "12733/12733 [==============================] - 96s 8ms/step - loss: 0.4364 - categorical_accuracy: 0.8057\n",
      "Epoch 17/30\n",
      "12733/12733 [==============================] - 96s 8ms/step - loss: 0.4445 - categorical_accuracy: 0.8016\n",
      "Epoch 18/30\n",
      "12733/12733 [==============================] - 98s 8ms/step - loss: 0.4394 - categorical_accuracy: 0.8065\n",
      "Epoch 19/30\n",
      "12733/12733 [==============================] - 99s 8ms/step - loss: 0.4342 - categorical_accuracy: 0.8064\n",
      "Epoch 20/30\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4327 - categorical_accuracy: 0.8092\n",
      "Epoch 21/30\n",
      "12733/12733 [==============================] - 116s 9ms/step - loss: 0.4251 - categorical_accuracy: 0.8114\n",
      "Epoch 22/30\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4171 - categorical_accuracy: 0.8152\n",
      "Epoch 23/30\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4242 - categorical_accuracy: 0.8130\n",
      "Epoch 24/30\n",
      "12733/12733 [==============================] - 116s 9ms/step - loss: 0.4399 - categorical_accuracy: 0.8059\n",
      "Epoch 25/30\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4378 - categorical_accuracy: 0.8057\n",
      "Epoch 26/30\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4624 - categorical_accuracy: 0.7891\n",
      "Epoch 27/30\n",
      "12733/12733 [==============================] - 113s 9ms/step - loss: 0.4527 - categorical_accuracy: 0.7964\n",
      "Epoch 28/30\n",
      "12733/12733 [==============================] - 116s 9ms/step - loss: 0.4446 - categorical_accuracy: 0.8000\n",
      "Epoch 29/30\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4414 - categorical_accuracy: 0.8040\n",
      "Epoch 30/30\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4363 - categorical_accuracy: 0.8058\n",
      "4259/4259 [==============================] - 11s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.720007\n",
      "Precision: 0.722746\n",
      "Recall: 0.974703\n",
      "F1 score: 0.830025\n",
      "Cohens kappa: 0.126165\n",
      "ROC AUC: 0.731024\n",
      "\\Confusion Matrix\n",
      "[[ 4957 35740]\n",
      " [ 2418 93167]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.721482\n",
      "Precision: 0.670102\n",
      "Recall: 0.122127\n",
      "F1 score: 0.206601\n",
      "Cohens kappa: 0.126648\n",
      "ROC AUC: 0.730649\n",
      "\\Confusion Matrix\n",
      "[[93383  2433]\n",
      " [35524  4942]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7207444856987717\n",
      "precision:  0.6964237752272595\n",
      "recall:  0.548415180855023\n",
      "f1_score:  0.5183130779884045\n",
      "cohen_kappa_score:  0.1264069250103902\n",
      "roc_auc_score:  0.7308368330734962\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 30, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4a52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/100\n",
      "12733/12733 [==============================] - 117s 9ms/step - loss: 0.5065 - categorical_accuracy: 0.7679\n",
      "Epoch 2/100\n",
      "12733/12733 [==============================] - 117s 9ms/step - loss: 0.5064 - categorical_accuracy: 0.7712\n",
      "Epoch 3/100\n",
      "12733/12733 [==============================] - 117s 9ms/step - loss: 0.4982 - categorical_accuracy: 0.7737\n",
      "Epoch 4/100\n",
      "12733/12733 [==============================] - 117s 9ms/step - loss: 0.4912 - categorical_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4916 - categorical_accuracy: 0.7771\n",
      "Epoch 6/100\n",
      "12733/12733 [==============================] - 116s 9ms/step - loss: 0.4772 - categorical_accuracy: 0.7834\n",
      "Epoch 7/100\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4685 - categorical_accuracy: 0.7871\n",
      "Epoch 8/100\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4644 - categorical_accuracy: 0.7900\n",
      "Epoch 9/100\n",
      "12733/12733 [==============================] - 113s 9ms/step - loss: 0.4612 - categorical_accuracy: 0.7946\n",
      "Epoch 10/100\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4516 - categorical_accuracy: 0.8048\n",
      "Epoch 11/100\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4525 - categorical_accuracy: 0.8011\n",
      "Epoch 12/100\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4511 - categorical_accuracy: 0.8013\n",
      "Epoch 13/100\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4525 - categorical_accuracy: 0.7999\n",
      "Epoch 14/100\n",
      "12733/12733 [==============================] - 116s 9ms/step - loss: 0.4553 - categorical_accuracy: 0.8008\n",
      "Epoch 15/100\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.4474 - categorical_accuracy: 0.8048\n",
      "Epoch 16/100\n",
      "12733/12733 [==============================] - 117s 9ms/step - loss: 0.4491 - categorical_accuracy: 0.8006\n",
      "Epoch 17/100\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.4424 - categorical_accuracy: 0.8035\n",
      "Epoch 18/100\n",
      " 8854/12733 [===================>..........] - ETA: 33s - loss: 0.4647 - categorical_accuracy: 0.7961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mCategoricalAccuracy()])\n\u001b[1;32m     13\u001b[0m           \u001b[38;5;66;03m#loss='binary_crossentropy',loss='categorical_crossentropy',\u001b[39;00m\n\u001b[1;32m     14\u001b[0m           \u001b[38;5;66;03m#loss='binary_crossentropy',  sparse_categorical_crossentropy     \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_series1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, batch_size=batch_size, validation_split=0.1\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# evaluate model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# predict\u001b[39;00m\n\u001b[1;32m     20\u001b[0m yhat_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_data)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[1;32m   1554\u001b[0m     )\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m         ):\n\u001b[1;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:636\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:2240\u001b[0m, in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2238\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_execution_mode \u001b[38;5;241m==\u001b[39m EAGER_MODE\n\u001b[0;32m-> 2240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:984\u001b[0m, in \u001b[0;36mContext.executing_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m EAGER_MODE:\n\u001b[1;32m    982\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_switches\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecuting_eagerly\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_local_data\u001b[38;5;241m.\u001b[39mis_eager\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 100, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2b9b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/7\n",
      "12733/12733 [==============================] - 135s 10ms/step - loss: 0.5271 - categorical_accuracy: 0.7590 - recall: 0.7591\n",
      "Epoch 2/7\n",
      "12733/12733 [==============================] - 127s 10ms/step - loss: 0.4981 - categorical_accuracy: 0.7730 - recall: 0.7732\n",
      "Epoch 3/7\n",
      "12733/12733 [==============================] - 137s 11ms/step - loss: 0.4748 - categorical_accuracy: 0.7831 - recall: 0.7832\n",
      "Epoch 4/7\n",
      "12733/12733 [==============================] - 140s 11ms/step - loss: 0.4545 - categorical_accuracy: 0.7921 - recall: 0.7923\n",
      "Epoch 5/7\n",
      "12733/12733 [==============================] - 160s 13ms/step - loss: 0.4375 - categorical_accuracy: 0.7998 - recall: 0.8001\n",
      "Epoch 6/7\n",
      "12733/12733 [==============================] - 126s 10ms/step - loss: 0.4235 - categorical_accuracy: 0.8055 - recall: 0.8057\n",
      "Epoch 7/7\n",
      "12733/12733 [==============================] - 129s 10ms/step - loss: 0.4122 - categorical_accuracy: 0.8099 - recall: 0.8102\n",
      "4259/4259 [==============================] - 12s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.719082\n",
      "Precision: 0.778379\n",
      "Recall: 0.838102\n",
      "F1 score: 0.807137\n",
      "Cohens kappa: 0.292793\n",
      "ROC AUC: 0.702396\n",
      "\\Confusion Matrix\n",
      "[[17888 22809]\n",
      " [15475 80110]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.719383\n",
      "Precision: 0.533315\n",
      "Recall: 0.439702\n",
      "F1 score: 0.482006\n",
      "Cohens kappa: 0.292008\n",
      "ROC AUC: 0.701902\n",
      "\\Confusion Matrix\n",
      "[[80246 15570]\n",
      " [22673 17793]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7192329141045772\n",
      "precision:  0.6558472315055024\n",
      "recall:  0.6389023394791269\n",
      "f1_score:  0.6445715517853932\n",
      "cohen_kappa_score:  0.29240036471053005\n",
      "roc_auc_score:  0.7021486385609363\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 7, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Recall()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "344dfe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n",
      "12733/12733 [==============================] - 136s 11ms/step - loss: 0.5259 - categorical_accuracy: 0.7594 - recall_1: 0.7594\n",
      "Epoch 2/2\n",
      "12733/12733 [==============================] - 135s 11ms/step - loss: 0.4949 - categorical_accuracy: 0.7749 - recall_1: 0.7750\n",
      "4259/4259 [==============================] - 13s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.739445\n",
      "Precision: 0.781973\n",
      "Recall: 0.871497\n",
      "F1 score: 0.824311\n",
      "Cohens kappa: 0.325956\n",
      "ROC AUC: 0.710135\n",
      "\\Confusion Matrix\n",
      "[[17471 23226]\n",
      " [12283 83302]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.740083\n",
      "Precision: 0.584762\n",
      "Recall: 0.429966\n",
      "F1 score: 0.495557\n",
      "Cohens kappa: 0.325942\n",
      "ROC AUC: 0.709718\n",
      "\\Confusion Matrix\n",
      "[[83461 12355]\n",
      " [23067 17399]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7397638719713535\n",
      "precision:  0.6833672636849764\n",
      "recall:  0.6507312355133418\n",
      "f1_score:  0.6599339870452097\n",
      "cohen_kappa_score:  0.3259489241309124\n",
      "roc_auc_score:  0.7099265705659015\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Recall()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d3350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 4 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/15\n",
      "12733/12733 [==============================] - 130s 10ms/step - loss: 0.5274 - categorical_accuracy: 0.7590 - recall_2: 0.7591\n",
      "Epoch 2/15\n",
      "12733/12733 [==============================] - 125s 10ms/step - loss: 0.4991 - categorical_accuracy: 0.7731 - recall_2: 0.7732\n",
      "Epoch 3/15\n",
      "12733/12733 [==============================] - 120s 9ms/step - loss: 0.4767 - categorical_accuracy: 0.7825 - recall_2: 0.7826\n",
      "Epoch 4/15\n",
      "12733/12733 [==============================] - 123s 10ms/step - loss: 0.4561 - categorical_accuracy: 0.7906 - recall_2: 0.7908\n",
      "Epoch 5/15\n",
      "12733/12733 [==============================] - 121s 10ms/step - loss: 0.4377 - categorical_accuracy: 0.7978 - recall_2: 0.7980\n",
      "Epoch 6/15\n",
      "12733/12733 [==============================] - 118s 9ms/step - loss: 0.4221 - categorical_accuracy: 0.8043 - recall_2: 0.8045\n",
      "Epoch 7/15\n",
      "12733/12733 [==============================] - 120s 9ms/step - loss: 0.4107 - categorical_accuracy: 0.8095 - recall_2: 0.8097\n",
      "Epoch 8/15\n",
      "12733/12733 [==============================] - 118s 9ms/step - loss: 0.4014 - categorical_accuracy: 0.8136 - recall_2: 0.8139\n",
      "Epoch 9/15\n",
      "12733/12733 [==============================] - 118s 9ms/step - loss: 0.3936 - categorical_accuracy: 0.8171 - recall_2: 0.8174\n",
      "Epoch 10/15\n",
      "12733/12733 [==============================] - 114s 9ms/step - loss: 0.3877 - categorical_accuracy: 0.8195 - recall_2: 0.8198\n",
      "Epoch 11/15\n",
      "12733/12733 [==============================] - 110s 9ms/step - loss: 0.3815 - categorical_accuracy: 0.8225 - recall_2: 0.8228\n",
      "Epoch 12/15\n",
      "12733/12733 [==============================] - 107s 8ms/step - loss: 0.3772 - categorical_accuracy: 0.8246 - recall_2: 0.8249\n",
      "Epoch 13/15\n",
      "12733/12733 [==============================] - 111s 9ms/step - loss: 0.3732 - categorical_accuracy: 0.8264 - recall_2: 0.8267\n",
      "Epoch 14/15\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.3701 - categorical_accuracy: 0.8279 - recall_2: 0.8282\n",
      "Epoch 15/15\n",
      "12733/12733 [==============================] - 115s 9ms/step - loss: 0.3671 - categorical_accuracy: 0.8296 - recall_2: 0.8300\n",
      "4259/4259 [==============================] - 12s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.704913\n",
      "Precision: 0.776767\n",
      "Recall: 0.812889\n",
      "F1 score: 0.794418\n",
      "Cohens kappa: 0.272753\n",
      "ROC AUC: 0.691958\n",
      "\\Confusion Matrix\n",
      "[[18367 22330]\n",
      " [17885 77700]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.705214\n",
      "Precision: 0.504027\n",
      "Recall: 0.451540\n",
      "F1 score: 0.476342\n",
      "Cohens kappa: 0.272072\n",
      "ROC AUC: 0.691581\n",
      "\\Confusion Matrix\n",
      "[[77836 17980]\n",
      " [22194 18272]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7050637648405512\n",
      "precision:  0.6403971669582651\n",
      "recall:  0.6322143078539627\n",
      "f1_score:  0.6353797667953671\n",
      "cohen_kappa_score:  0.27241251139162254\n",
      "roc_auc_score:  0.6917693134253399\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 15, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Recall()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
